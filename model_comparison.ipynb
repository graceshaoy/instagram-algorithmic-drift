{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdjoonHYpGmw",
        "outputId": "8bfdaf90-cdfc-4366-f8dc-ea5d0b5cce4d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Check if you're on Google drive or on your own machine.\n",
        "# Get path to your data.\n",
        "if ('google' in str(get_ipython())):\n",
        "    from google.colab import drive\n",
        "    drive.mount('ME', force_remount=True)\n",
        "    predir='ME/MyDrive/Colab_Notebooks/thesis'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjemVHgPpRDz"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGcVIZ3s950s"
      },
      "outputs": [],
      "source": [
        "from variables import groups,group_order,groupmap,group_titles,finished_usernames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-0XuZBPyxeK",
        "outputId": "71ad62cf-cf55-4ddb-fbc4-675184d836f8"
      },
      "outputs": [],
      "source": [
        "with open(predir+'/data/df_bypost_all.pkl', 'rb') as f:\n",
        "    df_bypost = pickle.load(f)\n",
        "\n",
        "df_bypost = df_bypost.dropna(subset=['post_times']).query('likes > 0')[df_bypost['username'].isin(finished_usernames)]\n",
        "\n",
        "# Extract cyclical time features\n",
        "def fourier_encode(df):\n",
        "    df['hour'] = df['post_times'].dt.hour\n",
        "    df['day_of_week'] = df['post_times'].dt.dayofweek  # 0=Monday\n",
        "    df['month'] = df['post_times'].dt.month\n",
        "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
        "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
        "    df['day_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
        "    df['day_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
        "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
        "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
        "    return df\n",
        "\n",
        "data = fourier_encode(df_bypost)\n",
        "\n",
        "\n",
        "# Time since last post (in hours)\n",
        "data['timedelta'] = data['timedelta'].fillna(-1)  # First post\n",
        "\n",
        "data['log_likes'] = np.log(data['likes']+1)\n",
        "\n",
        "# Rolling average of likes (past 10 posts)\n",
        "data['rolling_likes'] = (\n",
        "    data.groupby('username')['log_likes']\n",
        "    .transform(lambda x: x.shift(1).rolling(14, min_periods=1).mean())\n",
        ")\n",
        "\n",
        "# get the rate of change using np.gradient\n",
        "data['deriv1'] = np.gradient(data['rolling_likes'])\n",
        "data['deriv2'] = np.gradient(data['deriv1'])\n",
        "\n",
        "# make dummy variable for username\n",
        "dummies = pd.get_dummies(data['username'], columns=['username'], prefix = \"username\")\n",
        "data = pd.concat([data, dummies], axis=1)\n",
        "\n",
        "dummies = pd.get_dummies(data['group'], columns=['group'], prefix = 'group')\n",
        "data = pd.concat([data, dummies], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpE0qdIVzaTO"
      },
      "outputs": [],
      "source": [
        "REACHBACK = 14\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc4siarNzMlO",
        "outputId": "70bc7a9c-ca0b-49bb-961f-14d339a728aa"
      },
      "outputs": [],
      "source": [
        "split_before = pd.to_datetime('2024-07-01')\n",
        "data_before = data[data['date'] < split_before]\n",
        "data_before = data[data['date'] > pd.to_datetime('2023-11-01')]\n",
        "\n",
        "split = pd.to_datetime('2024-08-01')\n",
        "data_after = data[data['date'] >= split]\n",
        "data_after = data_after[data_after['date'] <= pd.to_datetime('2024-11-01')]\n",
        "\n",
        "# for the data after, only include [reachback:] for each account\n",
        "data_after = data_after.groupby('username').apply(lambda x: x.iloc[REACHBACK:]).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNDmZSTEzdi3"
      },
      "source": [
        "# models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSs1ZsyX0FmH"
      },
      "outputs": [],
      "source": [
        "def df_to_traintest(df, PrepData):\n",
        "  dataprepper = PrepData(df, reachback_length = REACHBACK)\n",
        "  dataset = [x for x in dataprepper.get_dataset()]\n",
        "\n",
        "  X, y = torch.cat([x[0] for x in dataset], dim=0), torch.tensor([x[1] for x in dataset])\n",
        "  X = X.reshape(len(dataset), dataprepper.reachback_length*X.shape[1])\n",
        "\n",
        "  train, val = torch.utils.data.random_split(list(zip(X,y)), [int(0.8*len(dataset)), len(dataset) - int(0.8*len(dataset))])\n",
        "\n",
        "  print(f\"Train size: {len(train)}\")\n",
        "  print(f\"Val size: {len(val)}\")\n",
        "\n",
        "  trainx, trainy = np.vstack([x[0] for x in train]), np.array([x[1] for x in train])\n",
        "  valx, valy = np.vstack([x[0] for x in val]), np.array([x[1] for x in val])\n",
        "  # testx, testy = np.vstack([x[0] for x in test]), np.array([x[1] for x in test])\n",
        "\n",
        "  # Convert numpy arrays to PyTorch datasets\n",
        "  train_dataset = torch.utils.data.TensorDataset(torch.tensor(trainx, dtype=torch.float32),\n",
        "                                                torch.tensor(trainy, dtype=torch.float32))\n",
        "  val_dataset = torch.utils.data.TensorDataset(torch.tensor(valx, dtype=torch.float32),\n",
        "                                              torch.tensor(valy, dtype=torch.float32))\n",
        "\n",
        "  # Create data loaders\n",
        "  batch_size = 64\n",
        "  train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "  val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "  return train_loader, val_loader\n",
        "\n",
        "def data_loader(df,PrepData, reachback_length=REACHBACK):\n",
        "    dataprepper = PrepData(df, single_user=True, reachback_length=reachback_length)\n",
        "    dataset = [x for x in dataprepper.get_dataset()]\n",
        "    x, y = np.vstack([x[0] for x in dataset]), np.array([x[1] for x in dataset])\n",
        "    x = x.reshape(len(dataset), dataprepper.reachback_length*x.shape[1])\n",
        "\n",
        "    dataset = torch.utils.data.TensorDataset(torch.tensor(x, dtype=torch.float32),\n",
        "                                             torch.tensor(y, dtype=torch.float32))\n",
        "    batch_size = 64\n",
        "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n",
        "    return loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOL2zqCN0GDX"
      },
      "outputs": [],
      "source": [
        "class OneBranchPrepData():\n",
        "    def __init__(self, df, reachback_length=REACHBACK,single_user=False):\n",
        "        self.df = df\n",
        "        self.reachback_length = reachback_length\n",
        "        self.users = df['username'].unique()\n",
        "        self.single_user = single_user\n",
        "\n",
        "        # Precompute reachback\n",
        "        self.reachback = []\n",
        "        if self.single_user:\n",
        "          for i in range(len(self.df) - (self.reachback_length)):\n",
        "              seq = self.df.iloc[i:i+self.reachback_length]\n",
        "              target = self.df.iloc[i+self.reachback_length]['likes']\n",
        "              target = np.log(target+1)\n",
        "              self.reachback.append((seq, target))\n",
        "        else:\n",
        "          for user in self.users:\n",
        "              user_df = self.df[self.df['username'] == user]\n",
        "              for i in range(len(user_df) - (self.reachback_length)):\n",
        "                  seq = user_df.iloc[i:i+self.reachback_length]\n",
        "                  target = user_df.iloc[i+self.reachback_length]['likes']\n",
        "                  target = np.log(target+1)\n",
        "                  self.reachback.append((seq, target))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        reachback, target = self.reachback[idx]\n",
        "\n",
        "        # Text embeddings (reachback_length x 384)\n",
        "        text_features = torch.tensor(\n",
        "            np.stack(reachback['caption_embedding'].values),\n",
        "            dtype=torch.float32\n",
        "        )\n",
        "\n",
        "        # # Time features (reachback_length x 6)\n",
        "        # time_features = torch.tensor(\n",
        "        #     reachback[['hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'month_sin', 'month_cos']].values,\n",
        "        #     dtype=torch.float32\n",
        "        # )\n",
        "\n",
        "        # Historical features (reachback_length x 2)\n",
        "        # historical_features = torch.tensor(\n",
        "        #     reachback[['rolling_likes','timedelta']].values,\n",
        "        #     dtype=torch.float32\n",
        "        # )\n",
        "\n",
        "        X = torch.cat([text_features], dim=1)\n",
        "        return X, target\n",
        "\n",
        "    def get_dataset(self):\n",
        "      if self.single_user:\n",
        "          for i in range(len(self.reachback)):\n",
        "              value = self.__getitem__(i)\n",
        "              # check if there is any nan\n",
        "              if value[0].isnan().any():\n",
        "                  continue\n",
        "              else:\n",
        "                yield value\n",
        "      else:\n",
        "          for user in self.users:\n",
        "              user_df = self.df[self.df['username'] == user]\n",
        "              for i in range(len(user_df) - self.reachback_length):\n",
        "                  value = self.__getitem__(i)\n",
        "                  # check if there is any nan\n",
        "                  if value[0].isnan().any():\n",
        "                      continue\n",
        "                  else:\n",
        "                    yield value\n",
        "\n",
        "class OneBranchLikesPredictor(nn.Module):\n",
        "    def __init__(self, sbert_dim=384, time_dim=6, historical_dim=0,\n",
        "                 hidden_dim=64, reachback_length=REACHBACK,\n",
        "                 verobose=False):\n",
        "        super().__init__()\n",
        "        self.reachback_length = reachback_length\n",
        "        self.sbert_dim = sbert_dim\n",
        "        self.time_dim = time_dim\n",
        "        self.historical_dim = historical_dim\n",
        "\n",
        "        self.verbose = verobose\n",
        "\n",
        "        # Text processing\n",
        "        self.text_fc = nn.Linear(sbert_dim, 128) # play with output dimension\n",
        "\n",
        "        # LSTM for temporal/historical patterns\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size= 128 + historical_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Final prediction\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Reshape input: (batch_size, reachback_length * total_features) ->\n",
        "        # (batch_size, reachback_length, total_features)\n",
        "        x = x.view(-1, self.reachback_length, self.sbert_dim + self.historical_dim)\n",
        "\n",
        "        # Split features\n",
        "        text_features = x[:, :, :self.sbert_dim]\n",
        "        # historical_features = x[:, :, self.sbert_dim:self.sbert_dim + self.historical_dim]\n",
        "        # historical_features = x[:, :, self.sbert_dim+self.time_dim:self.sbert_dim + self.historical_dim]\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"Text features shape: {text_features.shape}\")\n",
        "            # print(f\"Historical features shape: {historical_features.shape}\")\n",
        "\n",
        "        # Process text (batch_size, reachback_length, 128)\n",
        "        text_emb = self.text_fc(text_features)\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"text fc: {text_emb.shape}\")\n",
        "\n",
        "        # Process temporal features (batch_size, reachback_length, 6)\n",
        "        temporal_input = torch.cat([text_emb], dim=2)\n",
        "        lstm_out, _ = self.lstm(temporal_input)\n",
        "        lstm_last = lstm_out[:, -1, :]  # Last timestep\n",
        "\n",
        "        return self.fc(lstm_last)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5hHS_Y_XvMI"
      },
      "outputs": [],
      "source": [
        "class TwoBranchPrepData():\n",
        "    def __init__(self, df, reachback_length=REACHBACK,single_user=False):\n",
        "        self.df = df\n",
        "        self.reachback_length = reachback_length\n",
        "        self.users = df['username'].unique()\n",
        "        self.single_user = single_user\n",
        "\n",
        "        # Precompute reachback\n",
        "        self.reachback = []\n",
        "        if self.single_user:\n",
        "          for i in range(len(self.df) - (self.reachback_length)):\n",
        "              seq = self.df.iloc[i:i+self.reachback_length]\n",
        "              target = self.df.iloc[i+self.reachback_length]['likes']\n",
        "              target = np.log(target+1)\n",
        "              self.reachback.append((seq, target))\n",
        "        else:\n",
        "          for user in self.users:\n",
        "              user_df = self.df[self.df['username'] == user]\n",
        "              for i in range(len(user_df) - (self.reachback_length)):\n",
        "                  seq = user_df.iloc[i:i+self.reachback_length]\n",
        "                  target = user_df.iloc[i+self.reachback_length]['likes']\n",
        "                  target = np.log(target+1)\n",
        "                  self.reachback.append((seq, target))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        reachback, target = self.reachback[idx]\n",
        "\n",
        "        # Text embeddings (reachback_length x 384)\n",
        "        text_features = torch.tensor(\n",
        "            np.stack(reachback['caption_embedding'].values),\n",
        "            dtype=torch.float32\n",
        "        )\n",
        "\n",
        "        # Time features (reachback_length x 6)\n",
        "        time_features = torch.tensor(\n",
        "            reachback[['hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'month_sin', 'month_cos']].values,\n",
        "            dtype=torch.float32\n",
        "        )\n",
        "\n",
        "        # Historical features (reachback_length x 4)\n",
        "        historical_features = torch.tensor(\n",
        "            reachback[['rolling_likes', 'timedelta','deriv1','deriv2']].values,\n",
        "            dtype=torch.float32\n",
        "        )\n",
        "\n",
        "        X = torch.cat([text_features, time_features, historical_features], dim=1)\n",
        "        return X, target\n",
        "\n",
        "    def get_dataset(self):\n",
        "      if self.single_user:\n",
        "          for i in range(len(self.reachback)):\n",
        "              value = self.__getitem__(i)\n",
        "              # check if there is any nan\n",
        "              if value[0].isnan().any():\n",
        "                  continue\n",
        "              else:\n",
        "                yield value\n",
        "      else:\n",
        "          for user in self.users:\n",
        "              user_df = self.df[self.df['username'] == user]\n",
        "              for i in range(len(user_df) - self.reachback_length):\n",
        "                  value = self.__getitem__(i)\n",
        "                  # check if there is any nan\n",
        "                  if value[0].isnan().any():\n",
        "                      continue\n",
        "                  else:\n",
        "                    yield value\n",
        "\n",
        "class TwoBranchLikesPredictor(nn.Module):\n",
        "    def __init__(self, sbert_dim=384, time_dim=6, historical_dim=4,\n",
        "                 hidden_dim=64, reachback_length=REACHBACK,\n",
        "                 verobose=False):\n",
        "        super().__init__()\n",
        "        self.reachback_length = reachback_length\n",
        "        self.sbert_dim = sbert_dim\n",
        "        self.time_dim = time_dim\n",
        "        self.historical_dim = historical_dim\n",
        "\n",
        "        self.verbose = verobose\n",
        "\n",
        "        # Text processing\n",
        "        self.text_fc = nn.Linear(sbert_dim, 128) # play with output dimension\n",
        "        self.text_lstm = nn.LSTM(\n",
        "            input_size=128,\n",
        "            hidden_size=64,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # LSTM for temporal/historical patterns\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=time_dim + historical_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Final prediction\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(64 + hidden_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Reshape input: (batch_size, reachback_length * total_features) ->\n",
        "        # (batch_size, reachback_length, total_features)\n",
        "        x = x.view(-1, self.reachback_length, self.sbert_dim + self.time_dim + self.historical_dim)\n",
        "\n",
        "        # Split features\n",
        "        text_features = x[:, :, :self.sbert_dim]\n",
        "        time_features = x[:, :, self.sbert_dim:self.sbert_dim+self.time_dim]\n",
        "        historical_features = x[:, :, self.sbert_dim+self.time_dim:self.sbert_dim+self.time_dim + self.historical_dim]\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"Text features shape: {text_features.shape}\")\n",
        "            print(f\"Time features shape: {time_features.shape}\")\n",
        "            print(f\"Historical features shape: {historical_features.shape}\")\n",
        "\n",
        "        # Process text (batch_size, reachback_length, 128)\n",
        "        text_emb = self.text_fc(text_features)\n",
        "        text_lstm = self.text_lstm(text_emb)\n",
        "        text_last = text_lstm[0][:, -1, :]  # Last timestep\n",
        "        # text_agg = torch.mean(text_emb, dim=1)  # Average over sequence\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"text fc: {text_emb.shape}\")\n",
        "            print(f\"Text agg shape: {text_last.shape}\")\n",
        "\n",
        "        # Process temporal features (batch_size, reachback_length, 6)\n",
        "        temporal_input = torch.cat([time_features, historical_features], dim=2)\n",
        "        lstm_out, _ = self.lstm(temporal_input)\n",
        "        lstm_last = lstm_out[:, -1, :]  # Last timestep\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"LSTM output shape: {lstm_last.shape}\")\n",
        "\n",
        "        # Combine features\n",
        "        combined = torch.cat([text_last, lstm_last], dim=1)\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"Combined shape: {combined.shape}\")\n",
        "\n",
        "        return self.fc(combined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-X-Gc7yOzi3v"
      },
      "outputs": [],
      "source": [
        "class ThreeBranchPrepData():\n",
        "    def __init__(self, df, reachback_length=REACHBACK,single_user=False):\n",
        "        self.df = df\n",
        "        self.reachback_length = reachback_length\n",
        "        self.users = df['username'].unique()\n",
        "        self.reachback = []\n",
        "\n",
        "        for user in self.users:\n",
        "            user_df = self.df[self.df['username'] == user]\n",
        "            for i in range(len(user_df) - (self.reachback_length)):\n",
        "                seq = user_df.iloc[i:i+self.reachback_length]\n",
        "                target = user_df.iloc[i+self.reachback_length]['likes']\n",
        "                target = np.log(target+1)\n",
        "                self.reachback.append((seq, target))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        reachback, target = self.reachback[idx]\n",
        "\n",
        "        # Text embeddings (reachback_length x 384)\n",
        "        text_features = torch.tensor(\n",
        "            np.stack(reachback['caption_embedding'].values),\n",
        "            dtype=torch.float32\n",
        "        )\n",
        "\n",
        "        # Time features (reachback_length x 6)\n",
        "        time_features = torch.tensor(\n",
        "            reachback[['hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'month_sin', 'month_cos']].values,\n",
        "            dtype=torch.float32\n",
        "        )\n",
        "\n",
        "        # Historical features (reachback_length x 2)\n",
        "        historical_features = torch.tensor(\n",
        "            reachback[['rolling_likes', 'timedelta','deriv1','deriv2']].values,\n",
        "            dtype=torch.float32\n",
        "        )\n",
        "\n",
        "        # username dummy (reachback_length x 312)\n",
        "        username_features = torch.tensor(\n",
        "            reachback[reachback.columns[reachback.columns.str.startswith('username_')]].values,\n",
        "            dtype=torch.float32\n",
        "        )\n",
        "\n",
        "        X = torch.cat([text_features, time_features, historical_features, username_features], dim=1)\n",
        "        return X, target\n",
        "\n",
        "    def get_dataset(self):\n",
        "        for user in self.users:\n",
        "            user_df = self.df[self.df['username'] == user]\n",
        "            for i in range(len(user_df) - self.reachback_length):\n",
        "                value = self.__getitem__(i)\n",
        "                # check if there is any nan\n",
        "                if value[0].isnan().any():\n",
        "                    continue\n",
        "                else:\n",
        "                  yield value\n",
        "class ThreeBranchLikesPredictor(nn.Module):\n",
        "    def __init__(self, sbert_dim=384, time_dim=6, historical_dim=4,\n",
        "                 hidden_dim=64, reachback_length=REACHBACK,\n",
        "                 verobose=False):\n",
        "        super().__init__()\n",
        "        self.reachback_length = reachback_length\n",
        "        self.sbert_dim = sbert_dim\n",
        "        self.time_dim = time_dim\n",
        "        self.historical_dim = historical_dim\n",
        "        self.username_dim = 312\n",
        "\n",
        "        self.verbose = verobose\n",
        "\n",
        "        # Text processing\n",
        "        self.text_fc = nn.Linear(sbert_dim, 128) # play with output dimension\n",
        "        self.text_lstm = nn.LSTM(\n",
        "            input_size=128,\n",
        "            hidden_size=64,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # LSTM for temporal/historical patterns\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=time_dim + historical_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # linear for username\n",
        "        self.username_fc = nn.Linear(312, 1)\n",
        "\n",
        "        # Final prediction\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(64 + hidden_dim + 1, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Reshape input: (batch_size, reachback_length * total_features) ->\n",
        "        # (batch_size, reachback_length, total_features)\n",
        "        x = x.view(-1, self.reachback_length, self.sbert_dim + self.time_dim + self.historical_dim + self.username_dim)\n",
        "\n",
        "        # Split features\n",
        "        text_features = x[:, :, :self.sbert_dim]\n",
        "        time_features = x[:, :, self.sbert_dim:self.sbert_dim+self.time_dim]\n",
        "        historical_features = x[:, :, self.sbert_dim+self.time_dim:self.sbert_dim+self.time_dim + self.historical_dim]\n",
        "        username_features = x[:, :, -self.username_dim:]\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"Text features shape: {text_features.shape}\")\n",
        "            print(f\"Time features shape: {time_features.shape}\")\n",
        "            print(f\"Historical features shape: {historical_features.shape}\")\n",
        "            print(f\"Username features shape: {username_features.shape}\")\n",
        "\n",
        "        # Process text (batch_size, reachback_length, 128)\n",
        "        text_emb = self.text_fc(text_features)\n",
        "        text_lstm = self.text_lstm(text_emb)\n",
        "        text_last = text_lstm[0][:, -1, :]  # Last timestep\n",
        "        # text_agg = torch.mean(text_emb, dim=1)  # Average over sequence\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"text fc: {text_emb.shape}\")\n",
        "            print(f\"Text agg shape: {text_last.shape}\")\n",
        "\n",
        "        # Process temporal features (batch_size, reachback_length, 6)\n",
        "        temporal_input = torch.cat([time_features, historical_features], dim=2)\n",
        "        lstm_out, _ = self.lstm(temporal_input)\n",
        "        lstm_last = lstm_out[:, -1, :]  # Last timestep\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"LSTM output shape: {lstm_last.shape}\")\n",
        "\n",
        "        # Process username (batch_size, reachback_length, )\n",
        "        username_emb = self.username_fc(username_features)\n",
        "        username_agg = torch.mean(username_emb, dim=1)  # Average over sequence\n",
        "\n",
        "        # Combine features\n",
        "        combined = torch.cat([text_last, lstm_last, username_agg], dim=1)\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"Combined shape: {combined.shape}\")\n",
        "\n",
        "\n",
        "        return self.fc(combined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iftxexFC9jU"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, lr=0.001, num_epochs= 10, verbose = False):\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "  criterion = nn.MSELoss()\n",
        "\n",
        "  train_loss_history = []\n",
        "  val_loss_history = []\n",
        "  for epoch in tqdm(range(num_epochs)):\n",
        "      # Training phase\n",
        "      model.train()\n",
        "      train_loss = 0.0\n",
        "      for inputs, targets in train_loader:\n",
        "          inputs = inputs.to(device)\n",
        "          targets = targets.to(device).float()\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs.squeeze(), targets)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          train_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "      # Calculate average training loss\n",
        "      train_loss = train_loss / len(train_loader.dataset)\n",
        "\n",
        "      # Validation phase\n",
        "      model.eval()\n",
        "      val_loss = 0.0\n",
        "      with torch.no_grad():\n",
        "          for inputs, targets in val_loader:\n",
        "              inputs = inputs.to(device)\n",
        "              targets = targets.to(device).float()\n",
        "              outputs = model(inputs)\n",
        "              loss = criterion(outputs.squeeze(), targets)\n",
        "              val_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "      val_loss = val_loss / len(val_loader.dataset)\n",
        "\n",
        "      train_loss_history.append(train_loss)\n",
        "      val_loss_history.append(val_loss)\n",
        "\n",
        "      if verbose:\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print(f'Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}')\n",
        "        print('-' * 50)\n",
        "  return model, train_loss_history, val_loss_history\n",
        "\n",
        "def test_model(model, test_loader):\n",
        "  criterion = nn.MSELoss()\n",
        "  model.eval()\n",
        "  test_loss = 0.0\n",
        "  test_loss_unlog = 0.0\n",
        "  with torch.no_grad():\n",
        "      for inputs, targets in test_loader:\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs.squeeze(), targets)\n",
        "          test_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "          outputs_unlog = torch.exp(outputs)\n",
        "          targets_unlog = torch.exp(targets)\n",
        "          loss_unlog = criterion(outputs_unlog.squeeze(), targets_unlog)\n",
        "          test_loss_unlog += loss_unlog.item() * inputs.size(0)\n",
        "\n",
        "  test_loss = test_loss / len(test_loader.dataset)\n",
        "  test_loss_unlog = test_loss_unlog / len(test_loader.dataset)\n",
        "\n",
        "  return test_loss, test_loss_unlog"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3FVDSov0anG"
      },
      "source": [
        "# data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMVUh1Hb0aEC",
        "outputId": "72598b39-2eed-4eb1-ef30-d0947d7c20d7"
      },
      "outputs": [],
      "source": [
        "# Simple\n",
        "\n",
        "trainval_grouped1 = {}\n",
        "for group, usernames in groups.items():\n",
        "  group_df = data_before.query('username in @usernames')\n",
        "  print(group, len(group_df), '-'*30)\n",
        "  if len(group_df) > 100:\n",
        "    trainval_grouped1[group] = df_to_traintest(group_df, PrepData = OneBranchPrepData)\n",
        "  else:\n",
        "    print(f'{group} not enough data')\n",
        "  # trainval_grouped[group] = df_to_traintest(group_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dl6HFnUB0k7B",
        "outputId": "861aaa4f-193c-48f0-ffd8-70d9b054bbcd"
      },
      "outputs": [],
      "source": [
        "# two branch\n",
        "\n",
        "trainval_grouped2 = {}\n",
        "for group, usernames in groups.items():\n",
        "  group_df = data_before.query('username in @usernames')\n",
        "  print(group, len(group_df), '-'*30)\n",
        "  if len(group_df) > 100:\n",
        "    trainval_grouped2[group] = df_to_traintest(group_df, TwoBranchPrepData)\n",
        "  else:\n",
        "    print(f'{group} not enough data')\n",
        "  # trainval_grouped[group] = df_to_traintest(group_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K855Nljq0lY3",
        "outputId": "90f07543-2491-4b25-c6f3-496280768a0d"
      },
      "outputs": [],
      "source": [
        "# three branch\n",
        "\n",
        "trainval_grouped3 = {}\n",
        "for group, usernames in groups.items():\n",
        "  group_df = data_before.query('username in @usernames')\n",
        "  print(group, len(group_df), '-'*30)\n",
        "  if len(group_df) > 100:\n",
        "    trainval_grouped3[group] = df_to_traintest(group_df, ThreeBranchPrepData)\n",
        "  else:\n",
        "    print(f'{group} not enough data')\n",
        "  # trainval_grouped[group] = df_to_traintest(group_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJ3O5W2J1BIG"
      },
      "source": [
        "# train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ifnZNSU07px",
        "outputId": "0dca731c-597d-49b3-f911-e6234bc732ec"
      },
      "outputs": [],
      "source": [
        "model_grouped1 = {}\n",
        "for group, (train_loader, val_loader) in trainval_grouped1.items():\n",
        "  print(f\"Training {group}\")\n",
        "  model = OneBranchLikesPredictor(\n",
        "      sbert_dim=384,\n",
        "      reachback_length=REACHBACK,\n",
        "      verobose=False\n",
        "  )\n",
        "\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  # device = torch.device('cpu')\n",
        "  model = model.to(device)\n",
        "  print(f\"Using device: {device}\")\n",
        "\n",
        "  model, train_loss_history, val_loss_history = train_model(model, train_loader, val_loader, lr=0.001, verbose=False, num_epochs=25)\n",
        "\n",
        "  model_grouped1[group] = (model, train_loss_history, val_loss_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "PhxrpD_pXCeP",
        "outputId": "18973285-f800-4c09-bece-0e1b9777b3d8"
      },
      "outputs": [],
      "source": [
        "for i,group in enumerate(model_grouped1.keys()):\n",
        "  model, train_loss_history, val_loss_history = model_grouped1[group]\n",
        "  plt.subplot(3,5,i+1)\n",
        "  plt.text(0.5, 0.5, f'{group}:\\n{val_loss_history[-1]:.2f}', ha='center', va='center', transform=plt.gca().transAxes)\n",
        "  plt.plot(train_loss_history, label='Train Loss', )\n",
        "  plt.scatter(range(len(train_loss_history)), train_loss_history, color='tab:blue', s=5)\n",
        "  plt.plot(val_loss_history, label='Validation Loss')\n",
        "  plt.scatter(range(len(val_loss_history)), val_loss_history, color='tab:orange', s= 5)\n",
        "  if i % 5 != 0:\n",
        "    plt.yticks([])\n",
        "  else:\n",
        "    plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "\n",
        "plt.legend(loc = 'lower right', bbox_to_anchor=(2.1,0.3))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36nsvbbMYI82"
      },
      "outputs": [],
      "source": [
        "# model_grouped2deriv = {}\n",
        "# for group, (train_loader, val_loader) in trainval_grouped2deriv.items():\n",
        "#   print(f\"Training {group}\")\n",
        "#   model = TwoBranchDerivLikesPredictor(\n",
        "#       sbert_dim=384,\n",
        "#       reachback_length=REACHBACK,\n",
        "#       verobose=False\n",
        "#   )\n",
        "\n",
        "#   device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#   # device = torch.device('cpu')\n",
        "#   model = model.to(device)\n",
        "#   print(f\"Using device: {device}\")\n",
        "\n",
        "#   model, train_loss_history, val_loss_history = train_model(model, train_loader, val_loader, lr=0.001, verbose=False, num_epochs=20)\n",
        "\n",
        "#   model_grouped2deriv[group] = (model, train_loss_history, val_loss_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJdqeVkwYW6n"
      },
      "outputs": [],
      "source": [
        "# for i,group in enumerate(model_grouped2deriv.keys()):\n",
        "#   model, train_loss_history, val_loss_history = model_grouped2deriv[group]\n",
        "#   plt.subplot(3,5,i+1)\n",
        "#   plt.text(0.5, 0.5, f'{group}:\\n{val_loss_history[-1]:.2f}', ha='center', va='center', transform=plt.gca().transAxes)\n",
        "#   plt.plot(train_loss_history, label='Train Loss', )\n",
        "#   plt.scatter(range(len(train_loss_history)), train_loss_history, color='tab:blue', s=5)\n",
        "#   plt.plot(val_loss_history, label='Validation Loss')\n",
        "#   plt.scatter(range(len(val_loss_history)), val_loss_history, color='tab:orange', s= 5)\n",
        "#   if i % 5 != 0:\n",
        "#     plt.yticks([])\n",
        "#   else:\n",
        "#     plt.ylabel('Loss')\n",
        "#   plt.xlabel('Epoch')\n",
        "\n",
        "# plt.legend(loc = 'lower right', bbox_to_anchor=(2.1,0.3))\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmYzoPaJ1GKl",
        "outputId": "1835569e-b23d-4570-c739-6d1875545230"
      },
      "outputs": [],
      "source": [
        "model_grouped2 = {}\n",
        "for group, (train_loader, val_loader) in trainval_grouped2.items():\n",
        "  print(f\"Training {group}\")\n",
        "  model = TwoBranchLikesPredictor(\n",
        "      sbert_dim=384,\n",
        "      reachback_length=REACHBACK,\n",
        "      verobose=False\n",
        "  )\n",
        "\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  # device = torch.device('cpu')\n",
        "  model = model.to(device)\n",
        "  print(f\"Using device: {device}\")\n",
        "\n",
        "  model, train_loss_history, val_loss_history = train_model(model, train_loader, val_loader, lr=0.001, verbose=False, num_epochs=25)\n",
        "\n",
        "  model_grouped2[group] = (model, train_loss_history, val_loss_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "gLFiSLevXlVU",
        "outputId": "75284d4e-e482-4c11-904e-485d1cb900f2"
      },
      "outputs": [],
      "source": [
        "for i,group in enumerate(model_grouped2.keys()):\n",
        "  model, train_loss_history, val_loss_history = model_grouped2[group]\n",
        "  plt.subplot(3,5,i+1)\n",
        "  plt.text(0.5, 0.5, f'{group}:\\n{val_loss_history[-1]:.2f}', ha='center', va='center', transform=plt.gca().transAxes)\n",
        "  plt.plot(train_loss_history, label='Train Loss', )\n",
        "  plt.scatter(range(len(train_loss_history)), train_loss_history, color='tab:blue', s=5)\n",
        "  plt.plot(val_loss_history, label='Validation Loss')\n",
        "  plt.scatter(range(len(val_loss_history)), val_loss_history, color='tab:orange', s= 5)\n",
        "  if i % 5 != 0:\n",
        "    plt.yticks([])\n",
        "  else:\n",
        "    plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "\n",
        "plt.legend(loc = 'lower right', bbox_to_anchor=(2.1,0.3))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzgLo1nb1J7x",
        "outputId": "5e90ae53-4770-4ed8-dbb2-4fb9b073b344"
      },
      "outputs": [],
      "source": [
        "model_grouped3 = {}\n",
        "for group, (train_loader, val_loader) in trainval_grouped3.items():\n",
        "  print(f\"Training {group}\")\n",
        "  model = ThreeBranchLikesPredictor(\n",
        "      sbert_dim=384,\n",
        "      reachback_length=REACHBACK,\n",
        "      verobose=False\n",
        "  )\n",
        "\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  # device = torch.device('cpu')\n",
        "  model = model.to(device)\n",
        "  print(f\"Using device: {device}\")\n",
        "\n",
        "  model, train_loss_history, val_loss_history = train_model(model, train_loader, val_loader, lr=0.001, verbose=False, num_epochs=25)\n",
        "\n",
        "  model_grouped3[group] = (model, train_loss_history, val_loss_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "YdAwFvCZXq_O",
        "outputId": "b8dc03c4-f268-4d0e-d62c-0c7448255035"
      },
      "outputs": [],
      "source": [
        "for i,group in enumerate(model_grouped3.keys()):\n",
        "  model, train_loss_history, val_loss_history = model_grouped3[group]\n",
        "  plt.subplot(3,5,i+1)\n",
        "  plt.text(0.5, 0.5, f'{group}:\\n{val_loss_history[-1]:.2f}', ha='center', va='center', transform=plt.gca().transAxes)\n",
        "  plt.plot(train_loss_history, label='Train Loss', )\n",
        "  plt.scatter(range(len(train_loss_history)), train_loss_history, color='tab:blue', s=5)\n",
        "  plt.plot(val_loss_history, label='Validation Loss')\n",
        "  plt.scatter(range(len(val_loss_history)), val_loss_history, color='tab:orange', s= 5)\n",
        "  if i % 5 != 0:\n",
        "    plt.yticks([])\n",
        "  else:\n",
        "    plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "\n",
        "plt.legend(loc = 'lower right', bbox_to_anchor=(2.1,0.3))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_6eKkpT3Dpq",
        "outputId": "abd06626-7bff-43e8-e790-cae850fad1c9"
      },
      "outputs": [],
      "source": [
        "loss = {}\n",
        "# loss['one'] = [1.3042222829729941, 0.1322471123636643, 0.06989462532554612, 0.4563507162349325, 0.4942909843921661, 0.3941170771916707, 1.0540281456870002, 0.1729786756331027, 0.49412976740794595, 0.9720966219902039, 0.475496735415894, 0.5845634161707867, 0.785887829308371, 5.336733749934605]\n",
        "for branches,architecture in zip(['three'],[model_grouped3]):\n",
        "  final_loss = []\n",
        "  for group, (model, train_loss_history, val_loss_history) in architecture.items():\n",
        "    final_loss += [val_loss_history[-1]]\n",
        "    loss[branches] = final_loss\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0NuEWTNBQcj",
        "outputId": "e9d13e48-79ce-42fa-bd4c-91f350856fbf"
      },
      "outputs": [],
      "source": [
        "loss = {}\n",
        "# loss['one'] = [1.3042222829729941, 0.1322471123636643, 0.06989462532554612, 0.4563507162349325, 0.4942909843921661, 0.3941170771916707, 1.0540281456870002, 0.1729786756331027, 0.49412976740794595, 0.9720966219902039, 0.475496735415894, 0.5845634161707867, 0.785887829308371, 5.336733749934605]\n",
        "for branches,architecture in zip(['one','two'],[model_grouped1, model_grouped2]):\n",
        "  final_loss = []\n",
        "  for group, (model, train_loss_history, val_loss_history) in architecture.items():\n",
        "    final_loss += [val_loss_history[-1]]\n",
        "    loss[branches] = final_loss\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqMw-co2Xw5k"
      },
      "outputs": [],
      "source": [
        "loss = {'one': [0.8119317060648267, 0.09030180714887104, 0.05201016272190201, 0.17431352507205447, 0.6155957554249053, 0.23071729640165964, 0.6487047892531488, 0.14092928212549952, 0.38789024254513127, 1.0574390888214111, 0.8770792104417177, 0.6949891581010789, 0.11403568857506856, 0.44171265612787275], 'two': [0.9232050452789251, 0.0576316925134286, 0.03779425060759499, 0.15334679112587432, 0.16287271551629331, 0.08917510806111256, 0.6494924682008345, 0.1172322551569631, 0.3037592445751363, 0.8925648927688599, 0.5258060012818917, 0.6455977026436447, 0.04819292140681906, 0.2598202693642992]}\n",
        "loss['three'] =  [0.6245497078356081, 0.09411754319691115, 0.03141997889968589, 0.13235050077965715, 0.21072650399613888, 0.11033004692178808, 0.5246508916219076, 0.08843205912274403, 0.3231729140820822, 1.8471211194992065, 0.505800309002831, 0.6185696541775391, 0.05751745161684723, 0.30766715481877327]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "tPWG7l1FZ0u1",
        "outputId": "51d8b3c1-3162-4f1c-bca7-92bfd4cb4fb7"
      },
      "outputs": [],
      "source": [
        "# loss = {}\n",
        "# # loss['one'] = [1.3042222829729941, 0.1322471123636643, 0.06989462532554612, 0.4563507162349325, 0.4942909843921661, 0.3941170771916707, 1.0540281456870002, 0.1729786756331027, 0.49412976740794595, 0.9720966219902039, 0.475496735415894, 0.5845634161707867, 0.785887829308371, 5.336733749934605]\n",
        "# for branches,architecture in zip(['one','two','three'],[model_grouped1, model_grouped2, model_grouped3]):\n",
        "#   final_loss = []\n",
        "#   for group, (model, train_loss_history, val_loss_history) in architecture.items():\n",
        "#     final_loss += [val_loss_history[-1]]\n",
        "#     loss[branches] = final_loss\n",
        "\n",
        "\n",
        "plt.figure(figsize = (10,2))\n",
        "plt.scatter(loss.values(),['One'] * 14 + ['Two'] * 14 + ['Three'] * 14, marker = 'x', c = 'black', label = 'Final Loss (group)')\n",
        "# plot mean\n",
        "plt.scatter([np.median(x) for x in (loss.values())], ['One','Two','Three'], c = 'red', label = 'Median Loss')\n",
        "for median in [np.median(x) for x in (loss.values())]:\n",
        "  plt.axvline(median, color='red', linestyle='--', lw = 1)\n",
        "# plt.xlim([0,5])\n",
        "plt.xlabel('Validation Loss')\n",
        "plt.ylim([-1,3])\n",
        "plt.ylabel('Branches')\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.savefig(predir+'/figs/model_loss.png', dpi = 800)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbPwhqDy1aaP"
      },
      "source": [
        "# residuals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geByKJvOlUXY"
      },
      "source": [
        "## one branch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZzOeEs41Z5b"
      },
      "outputs": [],
      "source": [
        "residuals_grouped1 = {}\n",
        "\n",
        "for group, (model, train_loss_history, val_loss_history) in tqdm(model_grouped1.items()):\n",
        "  usernames = groups[group]\n",
        "  data_after_group = data_after.query(f'username in @usernames')\n",
        "  dataloader_after = data_loader(data_after_group, OneBranchPrepData)\n",
        "  dataloader_before = data_loader(data_before.query(f'username in @usernames'), OneBranchPrepData)\n",
        "  model.eval()\n",
        "  residuals_before = []\n",
        "  residuals_after = []\n",
        "  with torch.no_grad():\n",
        "      for inputs, targets in dataloader_after:\n",
        "          inputs, targets = inputs.to(device), targets.to(device)\n",
        "          outputs = model(inputs)\n",
        "          residuals_after.extend(targets - outputs.squeeze())\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, targets in dataloader_before:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model(inputs)\n",
        "        residuals_before.extend(targets - outputs.squeeze())\n",
        "\n",
        "  residuals_grouped1[group] = (residuals_before, residuals_after)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqNaZ944rkl7"
      },
      "outputs": [],
      "source": [
        "all_before1 = []\n",
        "all_after1 = []\n",
        "for group, (residuals_before, residuals_after) in residuals_grouped1.items():\n",
        "  all_before1.extend(residuals_before)\n",
        "  all_after1.extend(residuals_after)\n",
        "\n",
        "plt.hist(all_before1, alpha = 0.5, label = 'Before June 2023', density = True, bins = np.arange(-10,10,1))\n",
        "plt.hist(all_after1, alpha = 0.5, label = 'After February 2024', density = True, bins = np.arange(-10,10,1))\n",
        "plt.legend()\n",
        "plt.xlabel('Residuals (log likes)')\n",
        "# plt.savefig(predir+'/figs/residuals_two_branch.png', dpi = 800)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mgzR9RxlKpC"
      },
      "source": [
        "## two branch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snS3gL6u1k4E",
        "outputId": "1696312c-3713-4f30-b2c6-558e4829751c"
      },
      "outputs": [],
      "source": [
        "residuals_grouped2 = {}\n",
        "\n",
        "for group, (model, train_loss_history, val_loss_history) in tqdm(model_grouped2.items()):\n",
        "  usernames = groups[group]\n",
        "  data_after_group = data_after.query(f'username in @usernames')\n",
        "  dataloader_after = data_loader(data_after_group, TwoBranchPrepData)\n",
        "  dataloader_before = data_loader(data_before.query(f'username in @usernames'), TwoBranchPrepData)\n",
        "  model.eval()\n",
        "  residuals_before = []\n",
        "  residuals_after = []\n",
        "  with torch.no_grad():\n",
        "      for inputs, targets in dataloader_after:\n",
        "          inputs, targets = inputs.to(device), targets.to(device)\n",
        "          outputs = model(inputs)\n",
        "          residuals_after.extend(targets - outputs.squeeze())\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, targets in dataloader_before:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model(inputs)\n",
        "        residuals_before.extend(targets - outputs.squeeze())\n",
        "\n",
        "  residuals_grouped2[group] = (residuals_before, residuals_after)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "564qSfTpt6Dg",
        "outputId": "92cf40d0-e695-4e0c-f5e2-58a9a41bf957"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(3,5, figsize=(10,5), sharey = True, sharex = True)\n",
        "plt.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "for i, (ax,(group, (residuals_before, residuals_after))) in enumerate(zip(axes.flat,residuals_grouped2.items())):\n",
        "  ax.set_xlim([-12, 12])\n",
        "  # residuals_before = residuals_before_train + residuals_before_val\n",
        "  ax.hist(residuals_before, alpha = 0.5 ,density=True, label = 'Before Nov 2023 (train+val)', bins = np.arange(-10.5,10.5,1))\n",
        "  # ax.hist(residuals_before_train, alpha = 0.5 ,density=True, label = 'Before Nov 2023 (train)', bins = np.arange(-10.5,10.5,1))\n",
        "  # ax.hist(residuals_before_val, alpha = 0.5 ,density=True, label = 'Before Nov 2023 (val)', bins = np.arange(-10.5,10.5,1))\n",
        "  ax.hist(residuals_after, alpha = 0.5 ,density=True, label = 'After Feb 2024', bins = np.arange(-10.5,10.5,1))\n",
        "  ax.text(0.5, 0.75, group_titles[group], ha='center', va='center', transform=ax.transAxes)\n",
        "\n",
        "  # get ymax\n",
        "  ax.vlines(0, 0, 0.41, linestyles='dashed', colors='black', alpha = 0.25)\n",
        "\n",
        "  if i == len(residuals_grouped1) - 1:\n",
        "    # ax.remove()\n",
        "    ax.legend(loc = 'lower right', bbox_to_anchor=(2.1,0.3))\n",
        "\n",
        "\n",
        "fig.delaxes(axes[2][4])\n",
        "fig.supxlabel('Residuals (log likes)')\n",
        "fig.supylabel('Frequency', x=0.055)\n",
        "# fig.tight_layout()b\n",
        "\n",
        "# plt.savefig(predir+'/figs/residuals_large_feb2024.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "RfHZ8hn9G1_N",
        "outputId": "3196f2ba-e7b0-4d97-ebc7-bbdf236a8700"
      },
      "outputs": [],
      "source": [
        "all_before2 = []\n",
        "all_after2 = []\n",
        "for group, (residuals_before, residuals_after) in residuals_grouped2.items():\n",
        "  all_before2.extend(residuals_before)\n",
        "  all_after2.extend(residuals_after)\n",
        "\n",
        "plt.hist(all_before2, alpha = 0.5, label = 'Before June 2023', density = True, bins = np.arange(-10,10,1))\n",
        "plt.hist(all_after2, alpha = 0.5, label = 'After February 2024', density = True, bins = np.arange(-10,10,1))\n",
        "plt.legend()\n",
        "plt.xlabel('Residuals (log likes)')\n",
        "# plt.savefig(predir+'/figs/residuals_two_branch.png', dpi = 800)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbX_fhy3rtE9"
      },
      "source": [
        "## three branch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2KrOtKjlPTo",
        "outputId": "cdd339a4-02c7-4372-c766-bc3dda2406d3"
      },
      "outputs": [],
      "source": [
        "residuals_grouped3 = {}\n",
        "\n",
        "for group, (model, train_loss_history, val_loss_history) in tqdm(model_grouped3.items()):\n",
        "  usernames = groups[group]\n",
        "  data_after_group = data_after.query(f'username in @usernames')\n",
        "  if len(data_after_group) < 30:\n",
        "    continue\n",
        "  dataloader_after = data_loader(data_after_group, ThreeBranchPrepData)\n",
        "  dataloader_before = data_loader(data_before.query(f'username in @usernames'), ThreeBranchPrepData)\n",
        "  model.eval()\n",
        "  residuals_before = []\n",
        "  residuals_after = []\n",
        "  with torch.no_grad():\n",
        "      for inputs, targets in dataloader_after:\n",
        "          inputs, targets = inputs.to(device), targets.to(device)\n",
        "          outputs = model(inputs)\n",
        "          residuals_after.extend(targets - outputs.squeeze())\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, targets in dataloader_before:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model(inputs)\n",
        "        residuals_before.extend(targets - outputs.squeeze())\n",
        "\n",
        "  residuals_grouped3[group] = (residuals_before, residuals_after)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "w6PCQqLGr723",
        "outputId": "4eb28722-fa84-419d-8c97-c701b661c566"
      },
      "outputs": [],
      "source": [
        "all_before3 = []\n",
        "all_after3 = []\n",
        "for group, (residuals_before, residuals_after) in residuals_grouped3.items():\n",
        "  all_before3.extend(residuals_before)\n",
        "  all_after3.extend(residuals_after)\n",
        "\n",
        "plt.hist(all_before3, alpha = 0.5, label = 'Before June 2023', density = True, bins = np.arange(-10,10,1))\n",
        "plt.hist(all_after3, alpha = 0.5, label = 'After February 2024', density = True, bins = np.arange(-10,10,1))\n",
        "plt.legend()\n",
        "plt.xlabel('Residuals (log likes)')\n",
        "# plt.savefig(predir+'/figs/residuals_two_branch.png', dpi = 800)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2ZuH_PXrr7h"
      },
      "source": [
        "## agg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1t8R877SgFqU"
      },
      "outputs": [],
      "source": [
        "png1 = plt.imread(f\"{predir}/figs/onebranch.png\")\n",
        "png2 = plt.imread(f\"{predir}/figs/twobranch.png\")\n",
        "png3 = plt.imread(f\"{predir}/figs/threebranch.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "7Z9x_aLnhnhf",
        "outputId": "e95c08f2-123e-4b6f-d7ad-27e2cb80e4a7"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (12,4))\n",
        "plt.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(png1)\n",
        "plt.title('One Branch')\n",
        "plt.yticks([])\n",
        "plt.xticks([])\n",
        "# turn frame off\n",
        "# plt.axis('off')\n",
        "plt.gca().set(frame_on=False)\n",
        "plt.xlabel('Residuals (log likes)')\n",
        "plt.ylabel('Density')\n",
        "blue = mpatches.Patch(color='tab:blue', label = 'Before', alpha = 0.5)\n",
        "orange = mpatches.Patch(color='tab:orange', label = 'After', alpha = 0.5)\n",
        "plt.legend(handles=[blue, orange], loc = 'upper left', bbox_to_anchor = (0.15,0.98))\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(png2)\n",
        "plt.title('Two Branch')\n",
        "# plt.axis('off')\n",
        "plt.yticks([])\n",
        "plt.xticks([])\n",
        "plt.gca().set(frame_on=False)\n",
        "plt.xlabel('Residuals (log likes)')\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(png3)\n",
        "plt.title('Three Branch')\n",
        "# plt.axis('off')\n",
        "plt.yticks([])\n",
        "plt.xticks([])\n",
        "plt.gca().set(frame_on=False)\n",
        "plt.xlabel('Residuals (log likes)')\n",
        "\n",
        "# import matplotlib.patches as mpatches\n",
        "# blue = mpatches.Patch(color='tab:blue', label = 'Before', alpha = 0.5)\n",
        "# orange = mpatches.Patch(color='tab:orange', label = 'After', alpha = 0.5)\n",
        "# plt.legend(handles=[blue, orange], bbox_to_anchor = (1,1), loc = 'upper left')\n",
        "\n",
        "plt.savefig(predir+'/figs/residuals_compared_volatile.png', dpi = 800,bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "QjtuXmIQsA12",
        "outputId": "4d9c86d3-3db3-48e4-e036-772e3327b63c"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (12,4))\n",
        "plt.subplot(1,3,1)\n",
        "plt.hist(all_before1, alpha = 0.5, label = 'Before', density = True, bins = np.arange(-10,10,1))\n",
        "plt.hist(all_after1, alpha = 0.5, label = 'After', density = True, bins = np.arange(-10,10,1))\n",
        "plt.legend(loc='upper left')\n",
        "plt.xlabel('Residuals (log likes)')\n",
        "plt.ylabel('Density')\n",
        "plt.title('One Branch')\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.hist(all_before2, alpha = 0.5, label = 'Before June 2023', density = True, bins = np.arange(-10,10,1))\n",
        "plt.hist(all_after2, alpha = 0.5, label = 'After February 2024', density = True, bins = np.arange(-10,10,1))\n",
        "# plt.legend()\n",
        "plt.xlabel('Residuals (log likes)')\n",
        "plt.title('Two Branch')\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.hist(all_before3, alpha = 0.5, label = 'Before June 2023', density = True, bins = np.arange(-5,5,1))\n",
        "plt.hist(all_after3, alpha = 0.5, label = 'After February 2024', density = True, bins = np.arange(-5,5,1))\n",
        "# plt.legend(bbox_to_anchor = (1,1), loc = 'upper left')\n",
        "plt.xlabel('Residuals (log likes)')\n",
        "plt.title('Three Branch')\n",
        "\n",
        "plt.savefig(predir+'/figs/residuals_compared.png', dpi = 800,bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsOxm0BWQsoc"
      },
      "source": [
        "# split feb 2024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bjfm2EV7Qy_W",
        "outputId": "9660fdc2-6db0-4ef0-c696-c6766266b31f"
      },
      "outputs": [],
      "source": [
        "split_before = pd.to_datetime('2023-11-01')\n",
        "data_before = data[data['date'] < split_before]\n",
        "\n",
        "split = pd.to_datetime('2024-02-01')\n",
        "data_after = data[data['date'] >= split]\n",
        "\n",
        "# for the data after, only include [reachback:] for each account\n",
        "data_after = data_after.groupby('username').apply(lambda x: x.iloc[REACHBACK:]).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsBAjZm1RDR9",
        "outputId": "9e12d627-d272-400f-e0c3-bd590600495c"
      },
      "outputs": [],
      "source": [
        "# two branch\n",
        "\n",
        "trainval_grouped_feb2024 = {}\n",
        "for group, usernames in groups.items():\n",
        "  group_df = data_before.query('username in @usernames')\n",
        "  print(group, len(group_df), '-'*30)\n",
        "  if len(group_df) > 100:\n",
        "    trainval_grouped_feb2024[group] = df_to_traintest(group_df, TwoBranchPrepData)\n",
        "  else:\n",
        "    print(f'{group} not enough data')\n",
        "  # trainval_grouped[group] = df_to_traintest(group_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieXwd02CRUv-",
        "outputId": "84a91b3a-1139-424f-d7e1-0073865f31b9"
      },
      "outputs": [],
      "source": [
        "model_grouped_feb2024 = {}\n",
        "for group, (train_loader, val_loader) in trainval_grouped_feb2024.items():\n",
        "  print(f\"Training {group}\")\n",
        "  model = TwoBranchLikesPredictor(\n",
        "      sbert_dim=384,\n",
        "      reachback_length=REACHBACK,\n",
        "      verobose=False\n",
        "  )\n",
        "\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  # device = torch.device('cpu')\n",
        "  model = model.to(device)\n",
        "  print(f\"Using device: {device}\")\n",
        "\n",
        "  model, train_loss_history, val_loss_history = train_model(model, train_loader, val_loader, lr=0.001, verbose=False, num_epochs=20)\n",
        "\n",
        "  model_grouped_feb2024[group] = (model, train_loss_history, val_loss_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBI2qz9oRdwl",
        "outputId": "f465b0d6-aaa2-49d4-e7b1-46edbaa5d4cc"
      },
      "outputs": [],
      "source": [
        "residuals_grouped_feb2024 = {}\n",
        "\n",
        "for group, (model, train_loss_history, val_loss_history) in tqdm(model_grouped_feb2024.items()):\n",
        "  usernames = groups[group]\n",
        "  data_after_group = data_after.query(f'username in @usernames')\n",
        "  data_before_group = data_before.query(f'username in @usernames')\n",
        "  dataloader_after = data_loader(data_after_group, TwoBranchPrepData)\n",
        "  dataloader_before = data_loader(data_before_group, TwoBranchPrepData)\n",
        "  dataloader_before_train = trainval_grouped_feb2024[group][0]\n",
        "  dataloader_before_val = trainval_grouped_feb2024[group][1]\n",
        "\n",
        "  model.eval()\n",
        "  residuals_before = []\n",
        "  residuals_before_train = []\n",
        "  residuals_before_val = []\n",
        "  residuals_after = []\n",
        "  with torch.no_grad():\n",
        "      for inputs, targets in dataloader_after:\n",
        "          inputs, targets = inputs.to(device), targets.to(device)\n",
        "          outputs = model(inputs)\n",
        "          residuals_after.extend(targets - outputs.squeeze())\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, targets in dataloader_before_train:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model(inputs)\n",
        "        residuals_before_train.extend(targets - outputs.squeeze())\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, targets in dataloader_before_val:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model(inputs)\n",
        "        residuals_before_val.extend(targets - outputs.squeeze())\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, targets in dataloader_before:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model(inputs)\n",
        "        residuals_before.extend(targets - outputs.squeeze())\n",
        "\n",
        "  residuals_grouped_feb2024[group] = (residuals_before_train,residuals_before_val, residuals_before, residuals_after)\n",
        "  # residuals_grouped_feb2024[group] = (residuals_before, residuals_after)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmrfExO8Q0de"
      },
      "source": [
        "## plot residuals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "wyllhdTZWpoS",
        "outputId": "636487c3-f91e-4ea4-aa43-c10fb5a47122"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(3,5, figsize=(10,5), sharey = True, sharex = True)\n",
        "plt.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "for i, (ax,(group, (residuals_before_train,residuals_before_val, residuals_before, residuals_after))) in enumerate(zip(axes.flat,residuals_grouped_feb2024.items())):\n",
        "  ax.set_xlim([-12, 12])\n",
        "  ax.hist(residuals_before, alpha = 0.5 ,density=True, label = 'Before Nov 2023', bins = np.arange(-10.5,10.5,1))\n",
        "  # ax.hist(residuals_before_train, alpha = 0.5 ,density=True, label = 'Before Nov 2023 (train)', bins = np.arange(-10.5,10.5,1))\n",
        "  # ax.hist(residuals_before_val, alpha = 0.5 ,density=True, label = 'Before Nov 2023 (val)', bins = np.arange(-10.5,10.5,1))\n",
        "  ax.hist(residuals_after, alpha = 0.5 ,density=True, label = 'After Feb 2024', bins = np.arange(-10.5,10.5,1))\n",
        "  ax.text(0.5, 0.75, group_titles[group], ha='center', va='center', transform=ax.transAxes)\n",
        "\n",
        "  # get ymax\n",
        "  ax.vlines(0, 0, 0.41, linestyles='dashed', colors='black', alpha = 0.25)\n",
        "\n",
        "  if i == len(residuals_grouped1) - 1:\n",
        "    # ax.remove()\n",
        "    ax.legend(loc = 'lower right', bbox_to_anchor=(2.1,0.3))\n",
        "\n",
        "\n",
        "fig.delaxes(axes[2][4])\n",
        "fig.supxlabel('Residuals (log likes)')\n",
        "fig.supylabel('Frequency', x=0.055)\n",
        "# fig.tight_layout()b\n",
        "\n",
        "# plt.savefig(predir+'/figs/residuals_large_feb2024.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdbzsfKh59fc",
        "outputId": "682e656d-68fc-42be-d7a3-770f3f5989c3"
      },
      "outputs": [],
      "source": [
        "# t-test on averages before and after\n",
        "from scipy.stats import ttest_ind\n",
        "from scipy.stats import permutation_test\n",
        "from datetime import timedelta\n",
        "\n",
        "df_ttest = pd.DataFrame(columns=['group','tstat','pval','low','high'])\n",
        "\n",
        "for group, (residuals_before_train,residuals_before_val, residuals_before, residuals_after) in tqdm(residuals_grouped_feb2024.items()):\n",
        "\n",
        "  # ttest = ttest_ind(before, after, permutations=10_000)\n",
        "  ttest = ttest_ind(residuals_before, residuals_after)\n",
        "\n",
        "  interval = ttest.confidence_interval()\n",
        "  df_ttest = pd.concat([df_ttest, pd.DataFrame({'group': [group], 'tstat': [ttest[0]], 'pval': [ttest[1]], 'low':[interval[0]], 'high':[interval[1]]})])\n",
        "\n",
        "df_ttest['signif'] = (df_ttest['pval'] * 14) < 0.05 # bonferroni correction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "ll7xmPzd5_vH",
        "outputId": "63baacaa-1054-4f92-ab1d-234dcf1a1e7e"
      },
      "outputs": [],
      "source": [
        "fig, ax1 = plt.subplots(1,1, figsize=(10,5), sharey = True)\n",
        "\n",
        "plt.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "ax1.barh(df_ttest['group'][::-1], df_ttest['tstat'][::-1], alpha = 0.5)\n",
        "# go again for the significant ones\n",
        "ax1.barh(df_ttest.query('signif')['group'][::-1], df_ttest.query('signif')['tstat'][::-1], color = 'tab:blue', zorder = 2)\n",
        "\n",
        "# use fill between to color postive values green and negative values red\n",
        "ax1.fill_betweenx([0,len(groups)-1], -30, 0, color='red', alpha=0.25, zorder = 1)\n",
        "ax1.fill_betweenx([0,len(groups)-1], 0, 30, color='green', alpha=0.25, zorder = 1)\n",
        "\n",
        "ax1.grid(zorder=1)\n",
        "ax1.set_yticks(range(len(group_titles)), [group_titles.get(g, g) for g in groups.keys()][::-1])\n",
        "ax1.set_ylabel('Group')\n",
        "ax1.set_xlabel('T-Statistic')\n",
        "\n",
        "# plt.savefig(predir+'/figs/ttest_large_feb2024.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gR1_2u3_Qx2a"
      },
      "source": [
        "# split jan 2025"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "182-r5t3wZjW",
        "outputId": "734604a8-51f2-47d3-bb2d-13f19b1be9d8"
      },
      "outputs": [],
      "source": [
        "split_before = pd.to_datetime('2024-10-01')\n",
        "data_before = data[data['date'] < split_before]\n",
        "\n",
        "split = pd.to_datetime('2025-01-06')\n",
        "data_after = data[data['date'] >= split]\n",
        "\n",
        "# for the data after, only include [reachback:] for each account\n",
        "data_after = data_after.groupby('username').apply(lambda x: x.iloc[REACHBACK:]).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-RE06HbwZjZ",
        "outputId": "67a4ff31-b057-4f68-c500-3c6f186ba9a4"
      },
      "outputs": [],
      "source": [
        "# two branch\n",
        "\n",
        "trainval_grouped_jan2025 = {}\n",
        "for group, usernames in groups.items():\n",
        "  group_df = data_before.query('username in @usernames')\n",
        "  print(group, len(group_df), '-'*30)\n",
        "  if len(group_df) > 100:\n",
        "    trainval_grouped_jan2025[group] = df_to_traintest(group_df, TwoBranchPrepData)\n",
        "  else:\n",
        "    print(f'{group} not enough data')\n",
        "  # trainval_grouped[group] = df_to_traintest(group_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSOtIh2jwZjb",
        "outputId": "e5e8ff6b-2b85-4985-846d-8ad5d31ca14a"
      },
      "outputs": [],
      "source": [
        "model_grouped_jan2025= {}\n",
        "for group, (train_loader, val_loader) in trainval_grouped_jan2025.items():\n",
        "  print(f\"Training {group}\")\n",
        "  model = TwoBranchLikesPredictor(\n",
        "      sbert_dim=384,\n",
        "      reachback_length=REACHBACK,\n",
        "      verobose=False\n",
        "  )\n",
        "\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  # device = torch.device('cpu')\n",
        "  model = model.to(device)\n",
        "  print(f\"Using device: {device}\")\n",
        "\n",
        "  model, train_loss_history, val_loss_history = train_model(model, train_loader, val_loader, lr=0.001, verbose=False, num_epochs=20)\n",
        "\n",
        "  model_grouped_jan2025[group] = (model, train_loss_history, val_loss_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9nJ2xOdcnpb",
        "outputId": "92110309-a47b-4248-8c33-7f4be628fd72"
      },
      "outputs": [],
      "source": [
        "list(model_grouped_jan2025.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBNIiqqjceTa",
        "outputId": "bac6545c-3372-4cb1-8101-c0ff540dbb7a"
      },
      "outputs": [],
      "source": [
        "residuals_grouped_jan2025.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRKtHfaYwZjd",
        "outputId": "718c8aea-9a51-4cb3-a1e7-f441b0f1a11a"
      },
      "outputs": [],
      "source": [
        "residuals_grouped_jan2025 = {}\n",
        "\n",
        "for group, (model, train_loss_history, val_loss_history) in tqdm(model_grouped_jan2025.items()):\n",
        "  usernames = groups[group]\n",
        "  data_after_group = data_after.query(f'username in @usernames')\n",
        "  data_before_group = data_before.query(f'username in @usernames')\n",
        "  if len(data_after_group) < 30:\n",
        "    print(f'{group} not enough after data')\n",
        "    continue\n",
        "  if len(data_before_group) < 30:\n",
        "    print(f'{group} not enough before data')\n",
        "    continue\n",
        "  dataloader_after = data_loader(data_after_group, TwoBranchPrepData)\n",
        "  dataloader_before = data_loader(data_before_group, TwoBranchPrepData)\n",
        "  # dataloader_before_train = trainval_grouped_feb2024[group][0]\n",
        "  # dataloader_before_val = trainval_grouped_feb2024[group][1]\n",
        "\n",
        "  model.eval()\n",
        "  residuals_before = []\n",
        "  residuals_before_train = []\n",
        "  residuals_before_val = []\n",
        "  residuals_after = []\n",
        "  with torch.no_grad():\n",
        "      for inputs, targets in dataloader_after:\n",
        "          inputs, targets = inputs.to(device), targets.to(device)\n",
        "          outputs = model(inputs)\n",
        "          residuals_after.extend(targets - outputs.squeeze())\n",
        "\n",
        "  # with torch.no_grad():\n",
        "  #   for inputs, targets in dataloader_before_train:\n",
        "  #       inputs, targets = inputs.to(device), targets.to(device)\n",
        "  #       outputs = model(inputs)\n",
        "  #       residuals_before_train.extend(targets - outputs.squeeze())\n",
        "\n",
        "  # with torch.no_grad():\n",
        "  #   for inputs, targets in dataloader_before_val:\n",
        "  #       inputs, targets = inputs.to(device), targets.to(device)\n",
        "  #       outputs = model(inputs)\n",
        "  #       residuals_before_val.extend(targets - outputs.squeeze())\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, targets in dataloader_before:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model(inputs)\n",
        "        residuals_before.extend(targets - outputs.squeeze())\n",
        "\n",
        "  # residuals_grouped_feb2024[group] = (residuals_before_train,residuals_before_val, residuals_before, residuals_after)\n",
        "  residuals_grouped_jan2025[group] = (residuals_before, residuals_after)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr3xakW0wZje"
      },
      "source": [
        "## plot residuals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "BRc7qGRlwZjf",
        "outputId": "7e2513f3-22b8-43ee-a321-502d00d71477"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(3,5, figsize=(10,5), sharey = True, sharex = True)\n",
        "plt.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "for i, (ax,(group)) in enumerate(zip(axes.flat,group_order)):\n",
        "  ax.set_xlim([-12, 12])\n",
        "  if group in residuals_grouped_jan2025.keys():\n",
        "    residuals_before, residuals_after = residuals_grouped_jan2025[group]\n",
        "    ax.hist(residuals_before, alpha = 0.5 ,density=True, label = 'Before Nov 2023', bins = np.arange(-10.5,10.5,1))\n",
        "    # ax.hist(residuals_before_train, alpha = 0.5 ,density=True, label = 'Before Nov 2023 (train)', bins = np.arange(-10.5,10.5,1))\n",
        "    # ax.hist(residuals_before_val, alpha = 0.5 ,density=True, label = 'Before Nov 2023 (val)', bins = np.arange(-10.5,10.5,1))\n",
        "    ax.hist(residuals_after, alpha = 0.5 ,density=True, label = 'After Feb 2024', bins = np.arange(-10.5,10.5,1))\n",
        "    ax.vlines(0, 0, 0.41, linestyles='dashed', colors='black', alpha = 0.25)\n",
        "  else:\n",
        "    ax.text(0.5, 0.5, \"not enough data\", ha='center', va='center', transform=ax.transAxes, color = 'darkgrey')\n",
        "  ax.text(0.5, 0.75, group_titles[group], ha='center', va='center', transform=ax.transAxes)\n",
        "  # get ymax\n",
        "\n",
        "  if i == len(group_order) - 1:\n",
        "    # ax.remove()\n",
        "    ax.legend(loc = 'lower right', bbox_to_anchor=(2.1,0.3))\n",
        "\n",
        "\n",
        "fig.delaxes(axes[2][4])\n",
        "fig.supxlabel('Residuals (log likes)')\n",
        "fig.supylabel('Frequency', x=0.055)\n",
        "# fig.tight_layout()b\n",
        "\n",
        "# plt.savefig(predir+'/figs/residuals_large_feb2024.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AplYt7S9wZjg",
        "outputId": "e7225ea7-7a94-4c77-fe73-3eea0f60f578"
      },
      "outputs": [],
      "source": [
        "# t-test on averages before and after\n",
        "from scipy.stats import ttest_ind\n",
        "from scipy.stats import permutation_test\n",
        "from datetime import timedelta\n",
        "\n",
        "df_ttest = pd.DataFrame(columns=['group','tstat','pval','low','high'])\n",
        "\n",
        "for group, (residuals_before, residuals_after) in tqdm(residuals_grouped_jan2025.items()):\n",
        "\n",
        "  # ttest = ttest_ind(before, after, permutations=10_000)\n",
        "  ttest = ttest_ind(residuals_before, residuals_after)\n",
        "\n",
        "  interval = ttest.confidence_interval()\n",
        "  df_ttest = pd.concat([df_ttest, pd.DataFrame({'group': [group], 'tstat': [ttest[0]], 'pval': [ttest[1]], 'low':[interval[0]], 'high':[interval[1]]})])\n",
        "\n",
        "df_ttest['signif'] = (df_ttest['pval'] * 14) < 0.05 # bonferroni correction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "mA6FYf20wZjg",
        "outputId": "b4765b86-1623-4aa1-e91f-4072b6cee382"
      },
      "outputs": [],
      "source": [
        "fig, ax1 = plt.subplots(1,1, figsize=(10,5), sharey = True)\n",
        "\n",
        "plt.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "ax1.barh(df_ttest['group'][::-1], df_ttest['tstat'][::-1], alpha = 0.5)\n",
        "# go again for the significant ones\n",
        "ax1.barh(df_ttest.query('signif')['group'][::-1], df_ttest.query('signif')['tstat'][::-1], color = 'tab:blue', zorder = 2)\n",
        "\n",
        "# use fill between to color postive values green and negative values red\n",
        "ax1.fill_betweenx([0,len(groups)-1], -30, 0, color='red', alpha=0.25, zorder = 1)\n",
        "ax1.fill_betweenx([0,len(groups)-1], 0, 30, color='green', alpha=0.25, zorder = 1)\n",
        "\n",
        "ax1.grid(zorder=1)\n",
        "ax1.set_yticks(range(len(group_titles)), [group_titles.get(g, g) for g in groups.keys()][::-1])\n",
        "ax1.set_ylabel('Group')\n",
        "ax1.set_xlabel('T-Statistic')\n",
        "\n",
        "# plt.savefig(predir+'/figs/ttest_large_feb2024.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJuuicZ_QtvN"
      },
      "source": [
        "# split no meaning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s228soRMwyBD",
        "outputId": "dbb52f94-e65b-499f-f0bf-8ec4fa239dea"
      },
      "outputs": [],
      "source": [
        "split_before = pd.to_datetime('2024-07-01') # also try 6, 5, 4\n",
        "data_before = data[data['date'] < split_before]\n",
        "data_before = data_before[data_before['date'] > pd.to_datetime('2024-02-01')]\n",
        "\n",
        "split = pd.to_datetime('2024-08-01')\n",
        "data_after = data[data['date'] >= split]\n",
        "data_after = data_after[data_after['date'] <= pd.to_datetime('2024-11-01')]\n",
        "\n",
        "# for the data after, only include [reachback:] for each account\n",
        "data_after = data_after.groupby('username').apply(lambda x: x.iloc[REACHBACK:]).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsw-0E1NwyBI",
        "outputId": "23921a1d-3c48-42c3-fb87-598f7ddedfc4"
      },
      "outputs": [],
      "source": [
        "# two branch\n",
        "\n",
        "trainval_grouped_nomeaning = {}\n",
        "for group, usernames in groups.items():\n",
        "  group_df = data_before.query('username in @usernames')\n",
        "  print(group, len(group_df), '-'*30)\n",
        "  if len(group_df) > 100:\n",
        "    trainval_grouped_nomeaning[group] = df_to_traintest(group_df, TwoBranchPrepData)\n",
        "  else:\n",
        "    print(f'{group} not enough data')\n",
        "  # trainval_grouped[group] = df_to_traintest(group_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-MDr3dDwyBJ",
        "outputId": "fd8bc83a-c75b-48cf-860d-f840217b119a"
      },
      "outputs": [],
      "source": [
        "model_grouped_nomeaning= {}\n",
        "for group, (train_loader, val_loader) in trainval_grouped_nomeaning.items():\n",
        "  print(f\"Training {group}\")\n",
        "  model = TwoBranchLikesPredictor(\n",
        "      sbert_dim=384,\n",
        "      reachback_length=REACHBACK,\n",
        "      verobose=False\n",
        "  )\n",
        "\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  # device = torch.device('cpu')\n",
        "  model = model.to(device)\n",
        "  print(f\"Using device: {device}\")\n",
        "\n",
        "  model, train_loss_history, val_loss_history = train_model(model, train_loader, val_loader, lr=0.001, verbose=False, num_epochs=20)\n",
        "\n",
        "  model_grouped_nomeaning[group] = (model, train_loss_history, val_loss_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "m5H4Fcgpg_kU",
        "outputId": "727ecdfd-0af5-47f4-e862-492bb3c173d7"
      },
      "outputs": [],
      "source": [
        "for i,group in enumerate(model_grouped_nomeaning.keys()):\n",
        "  model, train_loss_history, val_loss_history = model_grouped_nomeaning[group]\n",
        "  plt.subplot(3,5,i+1)\n",
        "  plt.text(0.5, 0.5, f'{group}:\\n{val_loss_history[-1]:.2f}', ha='center', va='center', transform=plt.gca().transAxes)\n",
        "  plt.plot(train_loss_history, label='Train Loss', )\n",
        "  plt.scatter(range(len(train_loss_history)), train_loss_history, color='tab:blue', s=5)\n",
        "  plt.plot(val_loss_history, label='Validation Loss')\n",
        "  plt.scatter(range(len(val_loss_history)), val_loss_history, color='tab:orange', s= 5)\n",
        "  if i % 5 != 0:\n",
        "    plt.yticks([])\n",
        "  else:\n",
        "    plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "\n",
        "plt.legend(loc = 'lower right', bbox_to_anchor=(2.1,0.3))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzBDA6EOwyBM",
        "outputId": "5c5954ec-022f-491c-996b-08c692406f47"
      },
      "outputs": [],
      "source": [
        "residuals_grouped_nomeaning = {}\n",
        "\n",
        "for group, (model, train_loss_history, val_loss_history) in tqdm(model_grouped_nomeaning.items()):\n",
        "  usernames = groups[group]\n",
        "  data_after_group = data_after.query(f'username in @usernames')\n",
        "  data_before_group = data_before.query(f'username in @usernames')\n",
        "  if len(data_after_group) < 30:\n",
        "    print(f'{group} not enough after data')\n",
        "    continue\n",
        "  if len(data_before_group) < 30:\n",
        "    print(f'{group} not enough before data')\n",
        "    continue\n",
        "  dataloader_after = data_loader(data_after_group, TwoBranchPrepData)\n",
        "  dataloader_before = data_loader(data_before_group, TwoBranchPrepData)\n",
        "  dataloader_before_train = trainval_grouped_nomeaning[group][0]\n",
        "  dataloader_before_val = trainval_grouped_nomeaning[group][1]\n",
        "\n",
        "  model.eval()\n",
        "  residuals_before = []\n",
        "  residuals_before_train = []\n",
        "  residuals_before_val = []\n",
        "  residuals_after = []\n",
        "  with torch.no_grad():\n",
        "      for inputs, targets in dataloader_after:\n",
        "          inputs, targets = inputs.to(device), targets.to(device)\n",
        "          outputs = model(inputs)\n",
        "          residuals_after.extend(targets - outputs.squeeze())\n",
        "\n",
        "  # with torch.no_grad():\n",
        "  #   for inputs, targets in dataloader_before_train:\n",
        "  #       inputs, targets = inputs.to(device), targets.to(device)\n",
        "  #       outputs = model(inputs)\n",
        "  #       residuals_before_train.extend(targets - outputs.squeeze())\n",
        "\n",
        "  # with torch.no_grad():\n",
        "  #   for inputs, targets in dataloader_before_val:\n",
        "  #       inputs, targets = inputs.to(device), targets.to(device)\n",
        "  #       outputs = model(inputs)\n",
        "  #       residuals_before_val.extend(targets - outputs.squeeze())\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, targets in dataloader_before:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model(inputs)\n",
        "        residuals_before.extend(targets - outputs.squeeze())\n",
        "\n",
        "  residuals_grouped_nomeaning[group] = (residuals_before_train,residuals_before_val, residuals_before, residuals_after)\n",
        "  # residuals_grouped_nomeaning[group] = (residuals_before, residuals_after)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0g5dHZvy7z-a"
      },
      "outputs": [],
      "source": [
        "# with open(predir+'/residuals_grouped_nomeaning.pkl', 'wb') as f:\n",
        "#   pickle.dump(residuals_grouped_nomeaning, f)\n",
        "\n",
        "with open(predir + '/residuals_grouped_nomeaning.pkl', 'rb') as f:\n",
        "  residuals_grouped_nomeaning = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqjirfyKbqLt"
      },
      "outputs": [],
      "source": [
        "len(residuals_before_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "yWk0ExjkiWnm",
        "outputId": "97412bbf-4b48-42ff-f1a5-94d6c076ae6d"
      },
      "outputs": [],
      "source": [
        "all_before = []\n",
        "all_after = []\n",
        "for group, (residuals_before_train,residuals_before_val, residuals_before, residuals_after) in residuals_grouped_nomeaning.items():\n",
        "  all_before.extend(residuals_before)\n",
        "  all_after.extend(residuals_after)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.hist(all_before, alpha = 0.5 ,density=True, label = 'Before\\n(All)', bins = np.arange(-10.5,10.5,1))\n",
        "plt.hist(all_after, alpha = 0.5 ,density=True, label = 'After', bins = np.arange(-10.5,10.5,1))\n",
        "plt.xlabel('Residuals (log likes)')\n",
        "plt.ylabel('Density')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.hist(residuals_before_val, alpha = 0.5 ,density=True, label = 'Before\\n(Validation)', bins = np.arange(-10.5,10.5,1), color = 'tab:green')\n",
        "plt.hist(all_after, alpha = 0.5 ,density=True, label = 'After', bins = np.arange(-10.5,10.5,1), color = 'tab:orange')\n",
        "plt.xlabel('Residuals (log likes)')\n",
        "plt.legend()\n",
        "\n",
        "# plt.savefig(predir+'/figs/residuals_val_vs_all.png', dpi = 800)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vApNisYXwyBO"
      },
      "source": [
        "## plot residuals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEJIRczF71u_"
      },
      "outputs": [],
      "source": [
        "with open(predir+'/residuals_grouped_nomeaning.pkl', 'rb') as f:\n",
        "  residuals_grouped_nomeaning = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nv7LG3jgZMu",
        "outputId": "37e425a9-2b10-4b94-c888-401287a26d80"
      },
      "outputs": [],
      "source": [
        "# t-test on averages before and after\n",
        "# from scipy.stats import ttest_ind\n",
        "# from scipy.stats import permutation_test\n",
        "# from datetime import timedelta\n",
        "\n",
        "# df_ttest = pd.DataFrame(columns=['group','tstat','pval','low','high'])\n",
        "\n",
        "# for group, (residuals_before_train,residuals_before_val, residuals_before, residuals_after) in tqdm(residuals_grouped_nomeaning.items()):\n",
        "#   residuals_before = [x.cpu().numpy() for x in residuals_before]\n",
        "#   residuals_after = [x.cpu().numpy() for x in residuals_after]\n",
        "\n",
        "#   # ttest = ttest_ind(before, after, permutations=10_000)\n",
        "#   ttest = ttest_ind(residuals_before, residuals_after)\n",
        "\n",
        "#   interval = ttest.confidence_interval()\n",
        "#   df_ttest = pd.concat([df_ttest, pd.DataFrame({'group': [group], 'tstat': [ttest[0]], 'pval': [ttest[1]], 'low':[interval[0]], 'high':[interval[1]]})])\n",
        "\n",
        "# df_ttest['signif'] = (df_ttest['pval'] * 14) < 0.05 # bonferroni correction\n",
        "\n",
        "# t-test on averages before and after\n",
        "from scipy.stats import ttest_ind\n",
        "from scipy.stats import permutation_test\n",
        "from datetime import timedelta\n",
        "\n",
        "df_ttest = pd.DataFrame(columns=['group','tstat','pval','residual'])\n",
        "\n",
        "for group, (residuals_before_train,residuals_before_val, residuals_before, residuals_after) in tqdm(residuals_grouped_nomeaning.items()):\n",
        "\n",
        "    residuals_before = [x.cpu().numpy() for x in residuals_before]\n",
        "    residuals_after = [x.cpu().numpy() for x in residuals_after]\n",
        "\n",
        "    ttest = ttest_ind(residuals_before, residuals_after)\n",
        "    # interval = ttest.confidence_interval()\n",
        "    df_ttest = pd.concat([df_ttest, pd.DataFrame({'group': [group], 'tstat': [ttest[0]], 'pval': [ttest[1]], 'residual':True})])\n",
        "\n",
        "    before_ll = data_before.query('group == @group')['log_likes']\n",
        "    after_ll = data_after.query('group == @group')['log_likes']\n",
        "\n",
        "    ttest = ttest_ind(before_ll, after_ll)\n",
        "\n",
        "    df_ttest = pd.concat([df_ttest, pd.DataFrame({'group': [group], 'tstat': [ttest[0]], 'pval': [ttest[1]], 'residual':False})])\n",
        "\n",
        "df_ttest['signif'] = (df_ttest['pval'] * 14) < 0.05 # bonferroni correction\n",
        "\n",
        "df_ttest = pd.concat([df_ttest, pd.DataFrame({'group': ['healthleft','healthleft','queer','queer'], 'residual':[True,False,True,False]})])\n",
        "\n",
        "# # order df_ttest by group_order\n",
        "# df_ttest = df_ttest.set_index('group')\n",
        "# # fill in missing groups\n",
        "# df_ttest = df_ttest.reindex(group_order)\n",
        "# df_ttest = df_ttest.loc[group_order].reset_index()\n",
        "df_ttest['tstat'].fillna(0, inplace=True)\n",
        "df_ttest['signif'].fillna(False, inplace=True)\n",
        "df_ttest['signif_values'] = np.where(df_ttest['signif'], df_ttest['tstat'], 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "xm67JEcjjAXq",
        "outputId": "bb073199-36f6-4f4b-80b4-d122a682966a"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10,4))\n",
        "subfigs = fig.subfigures(1,2, width_ratios = [1,3], wspace= -0.1)\n",
        "\n",
        "axL = subfigs[1].subplots(3,5, sharey = True, sharex = True)\n",
        "plt.subplots_adjust(wspace=0, hspace=0)\n",
        "for i, (ax,(group)) in enumerate(zip(axL.flat,group_order)):\n",
        "  ax.set_xlim([-12, 12])\n",
        "  if group in residuals_grouped_nomeaning.keys():\n",
        "    residuals_before_train,residuals_before_val, residuals_before, residuals_after = residuals_grouped_nomeaning[group]\n",
        "    residuals_before = [x.cpu().numpy() for x in residuals_before]\n",
        "    residuals_after = [x.cpu().numpy() for x in residuals_after]\n",
        "    ax.hist(residuals_before, alpha = 0.5 ,density=True, label = 'Before', bins = np.arange(-10.5,10.5,1))\n",
        "    ax.hist(residuals_after, alpha = 0.5 ,density=True, label = 'After', bins = np.arange(-10.5,10.5,1))\n",
        "    ax.vlines(0, 0, 0.41, colors='black', alpha = 0.25, linestyles=\"dashed\")\n",
        "  else:\n",
        "    ax.text(0.5, 0.5, \"not enough data\", ha='center', va='center', transform=ax.transAxes, color = 'darkgrey')\n",
        "  ax.text(0.5, 0.75, group_titles[group], ha='center', va='center', transform=ax.transAxes)\n",
        "  # get ymax\n",
        "  ax.set_ylim([0,0.47])\n",
        "\n",
        "  if i == len(group_order) - 2:\n",
        "    ax.legend(loc = 'lower right', bbox_to_anchor=(2.9,0.3))\n",
        "  if i % 5 != 0:\n",
        "    ax.yaxis.set_visible(False)\n",
        "  if i == 9:\n",
        "    ax.xaxis.set_visible(False)\n",
        "\n",
        "  # if i%5 != 0:\n",
        "  #   ax.set_yticks([])\n",
        "  # else:\n",
        "  #   ax.set_yticks([0,0.2,0.4])\n",
        "\n",
        "# delete the last ax\n",
        "axL.flat[-1].remove()\n",
        "subfigs[1].supxlabel('Residuals (log likes)', y=-0.02)\n",
        "subfigs[1].supylabel('Density', x=0.055)\n",
        "\n",
        "#######################################\n",
        "axR = subfigs[0].subplots(1,1)\n",
        "axR.barh(df_ttest.query('residual == True')['group'][::-1], df_ttest.query('residual == True')['tstat'][::-1], alpha = 0.5)\n",
        "axR.barh(df_ttest.query('signif ==True and residual == True')['group'][::-1], df_ttest.query('signif ==True and residual == True')['tstat'][::-1], color = 'tab:blue', zorder = 2)\n",
        "\n",
        "axR.hlines(range(len(group_order)), xmin=0, xmax=df_ttest.query('residual == False')['tstat'], color='black', zorder = 4, alpha = 0.5, linestyles='dashed')\n",
        "# axR.hlines(, xmin=0, xmax=df_ttest.query('residual'), color='black', zorder = 4, alpha = 0.5, linestyles='dashed')\n",
        "axR.hlines(range(len(group_order)), xmin=0, xmax=df_ttest.query('residual == False')['signif_values'], color='black', zorder = 4)\n",
        "\n",
        "\n",
        "# use fill between to color postive values green and negative values red\n",
        "axR.fill_betweenx([-100,100], -100, 0, color='red', alpha=0.15, zorder = 1)\n",
        "axR.fill_betweenx([-100,100], 0, 100, color='green', alpha=0.15, zorder = 1)\n",
        "\n",
        "# set ylim xlim\n",
        "axR.set_ylim([-1,len(group_order)])\n",
        "axR.set_xlim([-25,25])\n",
        "\n",
        "axR.grid(zorder=1, alpha = 0.5,  linestyle='--')\n",
        "axR.set_yticks(range(len(group_titles)), [group_titles.get(g, g) for g in group_order][::-1])\n",
        "axR.set_xticks([-20,-10,0,10,20])\n",
        "\n",
        "# signif_patch = mpatches.Patch(color='tab:blue', alpha = 1, label = 'Significant')\n",
        "# insignif_patch = mpatches.Patch(color='tab:blue', alpha = 0.5, label = 'Insignificant')\n",
        "# axR.legend(handles=[signif_patch, insignif_patch], loc = 'lower left')\n",
        "\n",
        "subfigs[0].supxlabel('T-Statistic', y = 0)\n",
        "subfigs[0].supylabel('Group', x = -0.32)\n",
        "\n",
        "# plt.savefig(predir+'/figs/ttest_control.png',bbox_inches='tight', dpi = 800)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2Tcqhibf8x5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "rHZxvLkLlGWw"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "basic_analysis",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
