{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DA3XA8ACPVa",
        "outputId": "e153586e-f0c8-4cd6-e528-63626e0c26dc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Check if you're on Google drive or on your own machine.\n",
        "# Get path to your data.\n",
        "if ('google' in str(get_ipython())):\n",
        "    from google.colab import drive\n",
        "    drive.mount('ME', force_remount=True)\n",
        "    predir='ME/MyDrive/thesis_final'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwgJv4CZsGHZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import matplotlib.lines as mlines\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import sympy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1-M1xgj-ua7"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "class CPU_Unpickler(pickle.Unpickler):\n",
        "    def find_class(self, module, name):\n",
        "        if module == 'torch.storage' and name == '_load_from_bytes':\n",
        "            return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n",
        "        else: return super().find_class(module, name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TT2AB0_OEHMl"
      },
      "source": [
        "# notebook variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TD20v3eQDCfz"
      },
      "outputs": [],
      "source": [
        "from variables import groups,group_order,groupmap,group_titles,finished_usernames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7p5Xld8DENG",
        "outputId": "0a7dc159-0f35-4fd7-deeb-a1898fdcf8b5"
      },
      "outputs": [],
      "source": [
        "with open(predir+'/df_bypost_all.pkl', 'rb') as f:\n",
        "    df_bypost = pickle.load(f)\n",
        "\n",
        "df_bypost = df_bypost.dropna(subset=['post_times']).query('likes > 0')[df_bypost['username'].isin(finished_usernames)]\n",
        "\n",
        "# Extract cyclical time features\n",
        "def fourier_encode(df):\n",
        "    df['hour'] = df['post_times'].dt.hour\n",
        "    df['day_of_week'] = df['post_times'].dt.dayofweek  # 0=Monday\n",
        "    df['month'] = df['post_times'].dt.month\n",
        "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
        "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
        "    df['day_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
        "    df['day_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
        "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
        "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
        "    return df\n",
        "\n",
        "data = fourier_encode(df_bypost)\n",
        "\n",
        "\n",
        "# Time since last post (in hours)\n",
        "data['timedelta'] = data['timedelta'].fillna(-1)  # First post\n",
        "\n",
        "data['log_likes'] = np.log(data['likes']+1)\n",
        "\n",
        "# Rolling average of likes (past 14 posts)\n",
        "data['rolling_likes'] = (\n",
        "    data.groupby('username')['log_likes']\n",
        "    .transform(lambda x: x.shift(1).rolling(14, min_periods=1).mean())\n",
        ")\n",
        "\n",
        "# get the rate of change using np.gradient\n",
        "data['deriv1'] = np.gradient(data['rolling_likes'])\n",
        "data['deriv2'] = np.gradient(data['deriv1'])\n",
        "\n",
        "data = data[data['date'] > pd.to_datetime('2023-01-01')]\n",
        "\n",
        "df_bypost = df_bypost.query('username != \"them\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aT1z4717EMmz"
      },
      "outputs": [],
      "source": [
        "REACHBACK = 14\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsIcZVCTEP0r"
      },
      "source": [
        "# model functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OSD3Mv1EQyQ"
      },
      "outputs": [],
      "source": [
        "def df_to_traintest(df, PrepData):\n",
        "  dataprepper = PrepData(df, reachback_length = REACHBACK)\n",
        "  dataset = [x for x in dataprepper.get_dataset()]\n",
        "\n",
        "  X, y = torch.cat([x[0] for x in dataset], dim=0), torch.tensor([x[1] for x in dataset])\n",
        "  X = X.reshape(len(dataset), dataprepper.reachback_length*X.shape[1])\n",
        "\n",
        "  torch.manual_seed(42)\n",
        "  train, val = torch.utils.data.random_split(list(zip(X,y)), [int(0.8*len(dataset)), len(dataset) - int(0.8*len(dataset))])\n",
        "\n",
        "  # print(f\"Train size: {len(train)}\")\n",
        "  # print(f\"Val size: {len(val)}\")\n",
        "\n",
        "  trainx, trainy = np.vstack([x[0] for x in train]), np.array([x[1] for x in train])\n",
        "  valx, valy = np.vstack([x[0] for x in val]), np.array([x[1] for x in val])\n",
        "\n",
        "  # Convert numpy arrays to PyTorch datasets\n",
        "  train_dataset = torch.utils.data.TensorDataset(torch.tensor(trainx, dtype=torch.float32),\n",
        "                                                torch.tensor(trainy, dtype=torch.float32))\n",
        "  val_dataset = torch.utils.data.TensorDataset(torch.tensor(valx, dtype=torch.float32),\n",
        "                                              torch.tensor(valy, dtype=torch.float32))\n",
        "\n",
        "  # Create data loaders\n",
        "  batch_size = 64\n",
        "  train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "  val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size,shuffle=True, num_workers=0)\n",
        "\n",
        "  return train_loader, val_loader\n",
        "\n",
        "def data_loader(df,PrepData, reachback_length=REACHBACK):\n",
        "  dataprepper = PrepData(df, reachback_length=reachback_length)\n",
        "  dataset = [x for x in dataprepper.get_dataset()]\n",
        "\n",
        "  X, y = torch.cat([x[0] for x in dataset], dim=0), torch.tensor([x[1] for x in dataset])\n",
        "  X = X.reshape(len(dataset), dataprepper.reachback_length*X.shape[1])\n",
        "\n",
        "  dataset = torch.utils.data.TensorDataset(torch.tensor(X, dtype=torch.float32),\n",
        "                                            torch.tensor(y, dtype=torch.float32))\n",
        "  batch_size = 64\n",
        "  loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,shuffle=True, num_workers=12)\n",
        "  return loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwGuQHDXESy3"
      },
      "outputs": [],
      "source": [
        "class TwoBranchPrepData():\n",
        "    def __init__(self, df, reachback_length=REACHBACK):\n",
        "        self.df = df\n",
        "        self.reachback_length = reachback_length\n",
        "        self.users = df['username'].unique()\n",
        "\n",
        "        # Precompute reachback\n",
        "        self.reachback = []\n",
        "        for user in self.users:\n",
        "            user_df = self.df[self.df['username'] == user]\n",
        "            for i in range(len(user_df) - (self.reachback_length)):\n",
        "                seq = user_df.iloc[i:i+self.reachback_length]\n",
        "                target = user_df.iloc[i+self.reachback_length]['likes']\n",
        "                target = np.log(target+1)\n",
        "                self.reachback.append((seq, target))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        reachback, target = self.reachback[idx]\n",
        "\n",
        "        # Text embeddings (reachback_length x 384)\n",
        "        text_features = torch.tensor(\n",
        "            np.stack(reachback['caption_embedding'].values),\n",
        "            dtype=torch.float32\n",
        "        )\n",
        "\n",
        "        # Time features (reachback_length x 6)\n",
        "        time_features = torch.tensor(\n",
        "            reachback[['hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'month_sin', 'month_cos']].values,\n",
        "            dtype=torch.float32\n",
        "        )\n",
        "\n",
        "        # Historical features (reachback_length x 4)\n",
        "        historical_features = torch.tensor(\n",
        "            reachback[['rolling_likes', 'timedelta','deriv1','deriv2']].values,\n",
        "            dtype=torch.float32\n",
        "        )\n",
        "\n",
        "        X = torch.cat([text_features, time_features, historical_features], dim=1)\n",
        "        return X, target\n",
        "\n",
        "    def get_dataset(self):\n",
        "        for user in self.users:\n",
        "            user_df = self.df[self.df['username'] == user]\n",
        "            for i in range(len(user_df) - self.reachback_length):\n",
        "                value = self.__getitem__(i)\n",
        "                # check if there is any nan\n",
        "                if value[0].isnan().any():\n",
        "                    continue\n",
        "                else:\n",
        "                  yield value\n",
        "\n",
        "class TwoBranchLikesPredictor(nn.Module):\n",
        "    def __init__(self, sbert_dim=384, time_dim=6, historical_dim=4,\n",
        "                 hidden_dim=64, reachback_length=REACHBACK,\n",
        "                 verobose=False):\n",
        "        super().__init__()\n",
        "        self.reachback_length = reachback_length\n",
        "        self.sbert_dim = sbert_dim\n",
        "        self.time_dim = time_dim\n",
        "        self.historical_dim = historical_dim\n",
        "\n",
        "        self.verbose = verobose\n",
        "\n",
        "        # Text processing\n",
        "        self.text_fc = nn.Linear(sbert_dim, 128) # play with output dimension\n",
        "        self.text_lstm = nn.LSTM(\n",
        "            input_size=128,\n",
        "            hidden_size=64,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # LSTM for temporal/historical patterns\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=time_dim + historical_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Final prediction\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(64 + hidden_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Reshape input: (batch_size, reachback_length * total_features) ->\n",
        "        # (batch_size, reachback_length, total_features)\n",
        "        x = x.view(-1, self.reachback_length, self.sbert_dim + self.time_dim + self.historical_dim)\n",
        "\n",
        "        # Split features\n",
        "        text_features = x[:, :, :self.sbert_dim]\n",
        "        time_features = x[:, :, self.sbert_dim:self.sbert_dim+self.time_dim]\n",
        "        historical_features = x[:, :, self.sbert_dim+self.time_dim:self.sbert_dim+self.time_dim + self.historical_dim]\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"Text features shape: {text_features.shape}\")\n",
        "            print(f\"Time features shape: {time_features.shape}\")\n",
        "            print(f\"Historical features shape: {historical_features.shape}\")\n",
        "\n",
        "        # Process text (batch_size, reachback_length, 128)\n",
        "        text_emb = self.text_fc(text_features)\n",
        "        text_lstm = self.text_lstm(text_emb)\n",
        "        text_last = text_lstm[0][:, -1, :]  # Last timestep\n",
        "        # text_agg = torch.mean(text_emb, dim=1)  # Average over sequence\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"text fc: {text_emb.shape}\")\n",
        "            print(f\"Text agg shape: {text_last.shape}\")\n",
        "\n",
        "        # Process temporal features (batch_size, reachback_length, 6)\n",
        "        temporal_input = torch.cat([time_features, historical_features], dim=2)\n",
        "        lstm_out, _ = self.lstm(temporal_input)\n",
        "        lstm_last = lstm_out[:, -1, :]  # Last timestep\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"LSTM output shape: {lstm_last.shape}\")\n",
        "\n",
        "        # Combine features\n",
        "        combined = torch.cat([text_last, lstm_last], dim=1)\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"Combined shape: {combined.shape}\")\n",
        "\n",
        "        return self.fc(combined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mV24zp4QEVKJ"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, lr=0.001, num_epochs= 10, verbose = False):\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "  criterion = nn.MSELoss()\n",
        "\n",
        "  train_loss_history = []\n",
        "  val_loss_history = []\n",
        "  for epoch in tqdm(range(num_epochs)):\n",
        "      # Training phase\n",
        "      model.train()\n",
        "      train_loss = 0.0\n",
        "      for inputs, targets in train_loader:\n",
        "          inputs = inputs.to(device)\n",
        "          targets = targets.to(device).float()\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs.squeeze(), targets)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          train_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "      # Calculate average training loss\n",
        "      train_loss = train_loss / len(train_loader.dataset)\n",
        "\n",
        "      # Validation phase\n",
        "      model.eval()\n",
        "      val_loss = 0.0\n",
        "      with torch.no_grad():\n",
        "          for inputs, targets in val_loader:\n",
        "              inputs = inputs.to(device)\n",
        "              targets = targets.to(device).float()\n",
        "              outputs = model(inputs)\n",
        "              loss = criterion(outputs.squeeze(), targets)\n",
        "              val_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "      val_loss = val_loss / len(val_loader.dataset)\n",
        "\n",
        "      train_loss_history.append(train_loss)\n",
        "      val_loss_history.append(val_loss)\n",
        "\n",
        "      if verbose:\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print(f'Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}')\n",
        "        print('-' * 50)\n",
        "  return model, train_loss_history, val_loss_history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gRJPBe1Uo4f"
      },
      "source": [
        "# Split control"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwgXpZF8zaje",
        "outputId": "0ed9a3bd-f385-4cd7-eadd-19aacd0cf742"
      },
      "outputs": [],
      "source": [
        "# split control\n",
        "\n",
        "split_before = pd.to_datetime('2024-07-01')\n",
        "data_before = data[data['date'] < split_before]\n",
        "data_before = data_before[data_before['date'] > pd.to_datetime('2024-02-01')]\n",
        "\n",
        "split = pd.to_datetime('2024-08-01')\n",
        "data_after = data[data['date'] >= split]\n",
        "data_after = data_after[data_after['date'] <= pd.to_datetime('2024-11-01')]\n",
        "\n",
        "# for the data after, only include [reachback:] for each account\n",
        "data_after = data_after.groupby('username').apply(lambda x: x.iloc[REACHBACK:]).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYg9r3IrNSR_"
      },
      "source": [
        "### get residuals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gohgRnBFUqt7"
      },
      "outputs": [],
      "source": [
        "# two branch\n",
        "\n",
        "trainval_grouped_nomeaning = {}\n",
        "for group, usernames in groups.items():\n",
        "  group_df = data_before.query('group == @group')\n",
        "  print(group, len(group_df), '-'*30)\n",
        "  if len(group_df) > 100:\n",
        "    trainval_grouped_nomeaning[group] = df_to_traintest(group_df, TwoBranchPrepData)\n",
        "  else:\n",
        "    print(f'{group} not enough data')\n",
        "\n",
        "model_grouped_nomeaning= {}\n",
        "for group, (train_loader, val_loader) in trainval_grouped_nomeaning.items():\n",
        "  print(f\"Training {group}\")\n",
        "  model = TwoBranchLikesPredictor(\n",
        "      sbert_dim=384,\n",
        "      reachback_length=REACHBACK,\n",
        "      verobose=False\n",
        "  )\n",
        "\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  # device = torch.device('cpu')\n",
        "  model = model.to(device)\n",
        "  print(f\"Using device: {device}\")\n",
        "\n",
        "  torch.save(model.state_dict(), predir+f'/models/{group}_{split_before}.pt')\n",
        "\n",
        "  model, train_loss_history, val_loss_history = train_model(model, train_loader, val_loader, lr=0.001, verbose=False, num_epochs=20)\n",
        "\n",
        "  model_grouped_nomeaning[group] = (model, train_loss_history, val_loss_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJLBwdEV4iR5"
      },
      "outputs": [],
      "source": [
        "model_grouped_nomeaning = {}\n",
        "for group in group_order:\n",
        "  model = TwoBranchLikesPredictor(\n",
        "      sbert_dim=384,\n",
        "      reachback_length=REACHBACK,\n",
        "      verobose=False\n",
        "  )\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  model = model.to(device)\n",
        "  if torch.cuda.is_available():\n",
        "    model.load_state_dict(torch.load(predir+f'/models/{group}_{split_before}.pt'))\n",
        "  else:\n",
        "    model.load_state_dict(torch.load(predir+f'/models/{group}_{split_before}.pt', map_location=torch.device('cpu')))\n",
        "  model_grouped_nomeaning[group] = (model, [],[])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afIUXUTaUwU1",
        "outputId": "9f6eeee0-68ba-4825-cfdb-443d1291b482"
      },
      "outputs": [],
      "source": [
        "# residuals_grouped_nomeaning = {}\n",
        "\n",
        "for group, (model, train_loss_history, val_loss_history) in tqdm(model_grouped_nomeaning.items()):\n",
        "  usernames = groups[group]\n",
        "  data_after_group = data_after.query(f'group == @group')\n",
        "  data_before_group = data_before.query(f'group == @group')\n",
        "  if len(data_after_group) < 30:\n",
        "    print(f'{group} not enough after data')\n",
        "    continue\n",
        "  if len(data_before_group) < 30:\n",
        "    print(f'{group} not enough before data')\n",
        "    continue\n",
        "  dataloader_after = data_loader(data_after_group, TwoBranchPrepData)\n",
        "  dataloader_before_train = trainval_grouped_nomeaning[group][0]\n",
        "  dataloader_before_val = trainval_grouped_nomeaning[group][1]\n",
        "\n",
        "  model.eval()\n",
        "  residuals_before = []\n",
        "  residuals_after = []\n",
        "  residuals_before_train = []\n",
        "  residuals_before_val = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for inputs, targets in dataloader_after:\n",
        "          inputs, targets = inputs.to(device), targets.to(device)\n",
        "          outputs = model(inputs)\n",
        "          residuals_after.extend(targets - outputs.squeeze())\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, targets in dataloader_before_train:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model(inputs)\n",
        "        residuals_before_train.extend(targets - outputs.squeeze())\n",
        "        residuals_before.extend(targets - outputs.squeeze())\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, targets in dataloader_before_val:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model(inputs)\n",
        "        residuals_before_val.extend(targets - outputs.squeeze())\n",
        "        residuals_before.extend(targets - outputs.squeeze())\n",
        "\n",
        "  residuals_grouped_nomeaning[group] = (residuals_before_train,residuals_before_val, residuals_before, residuals_after)\n",
        "\n",
        "# with open(predir+'/residuals/residuals_grouped_nomeaning.pkl', 'wb') as f:\n",
        "#   pickle.dump(residuals_grouped_nomeaning, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60y5AU1xcDc9",
        "outputId": "6f785855-4eaa-4614-8faa-006e04e7694d"
      },
      "outputs": [],
      "source": [
        "# turn from torch to numpy array\n",
        "for group in tqdm(residuals_grouped_nomeaning.keys()):\n",
        "  # for before in before_dates:\n",
        "  residuals_before_train,residuals_before_val, residuals_before, residuals_after = residuals_grouped_nomeaning[group]\n",
        "  residuals_before_train = [float(x) for x in residuals_before_train]\n",
        "  residuals_before_val = [float(x) for x in residuals_before_val]\n",
        "  residuals_before = [float(x) for x in residuals_before]\n",
        "  residuals_after = [float(x) for x in residuals_after]\n",
        "  residuals_grouped_nomeaning[group] = residuals_before_train,residuals_before_val, residuals_before, residuals_after\n",
        "\n",
        "with open(predir+'/residuals/residuals_control.pkl', 'wb') as f:\n",
        "  pickle.dump(residuals_grouped_nomeaning, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9K1ABfnjOwG"
      },
      "source": [
        "# split 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZPvGFHrjMlt",
        "outputId": "0cef8f16-2d7f-4b16-ac28-9c196697f17c"
      },
      "outputs": [],
      "source": [
        "date_policy1 = pd.to_datetime('2024-02-09')\n",
        "earliest_before = pd.to_datetime('2023-10-01')\n",
        "\n",
        "before_dates = pd.date_range(start=earliest_before - pd.Timedelta(days=1), end=date_policy1 - pd.Timedelta(days=14), freq='1ME') + pd.Timedelta(days=1)\n",
        "len(before_dates), before_dates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1_Uag1UNsF7"
      },
      "source": [
        "### get residuals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwpjML9OOJhX",
        "outputId": "cedc169a-0a7e-4067-d075-3f218ac4b6cb"
      },
      "outputs": [],
      "source": [
        "models1 = dict()\n",
        "residuals1 = dict()\n",
        "\n",
        "data_after = data[data['date'] >= date_policy1]\n",
        "# for group in tqdm(group_order):\n",
        "for group in ['queer']:\n",
        "  data_after_group = data_after[data_after['group'] == group]\n",
        "\n",
        "  data_group = data[data['group'] == group]\n",
        "  for before in before_dates:\n",
        "    data_before_group = data_group[data_group['date'] < before]\n",
        "    if len(data_before_group) < 100:\n",
        "      print(f\"Not enough data for {group} before {before}\")\n",
        "    else:\n",
        "      # dataloaders\n",
        "      train_loader, val_loader = df_to_traintest(data_before_group, TwoBranchPrepData)\n",
        "      after_loader = data_loader(data_after_group, TwoBranchPrepData)\n",
        "\n",
        "      # train\n",
        "      model = TwoBranchLikesPredictor(\n",
        "          sbert_dim = 384, reachback_length=REACHBACK\n",
        "      ).to(device)\n",
        "\n",
        "      model, train_loss_history, val_loss_history = train_model(model, train_loader, val_loader, lr=0.001, num_epochs= 20, verbose = False)\n",
        "\n",
        "      torch.save(model.state_dict(), f'{predir}/models/{group}_{before}.pt')\n",
        "\n",
        "      # get residuals\n",
        "      model.eval()\n",
        "      residuals_train, residuals_val, residuals_before, residuals_after = [], [], [], []\n",
        "      with torch.no_grad():\n",
        "          for inputs, targets in train_loader:\n",
        "              inputs, targets = inputs.to(device), targets.to(device)\n",
        "              outputs = model(inputs)\n",
        "              residuals_train.extend(targets - outputs.squeeze())\n",
        "              residuals_before.extend(targets - outputs.squeeze())\n",
        "\n",
        "      with torch.no_grad():\n",
        "          for inputs, targets in val_loader:\n",
        "              inputs, targets = inputs.to(device), targets.to(device)\n",
        "              outputs = model(inputs)\n",
        "              residuals_val.extend(targets - outputs.squeeze())\n",
        "              residuals_before.extend(targets - outputs.squeeze())\n",
        "\n",
        "      with torch.no_grad():\n",
        "          for inputs, targets in after_loader:\n",
        "              inputs, targets = inputs.to(device), targets.to(device)\n",
        "              outputs = model(inputs)\n",
        "              residuals_after.extend(targets - outputs.squeeze())\n",
        "\n",
        "      group_residuals = (residuals_train, residuals_val, residuals_before, residuals_after)\n",
        "      with open(f'{predir}/residuals/{group}_{before}.pkl', 'wb') as f:\n",
        "        pickle.dump(group_residuals, f)\n",
        "\n",
        "      # residuals1[group][before] = (residuals_train, residuals_val, residuals_before, residuals_after)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cb3OstDgtw16",
        "outputId": "f8e4fb5d-1798-4995-c227-29819fcac56b"
      },
      "outputs": [],
      "source": [
        "residuals1 = dict()\n",
        "for group in tqdm(group_order):\n",
        "  residuals1[group] = dict()\n",
        "  for before in before_dates:\n",
        "    try:\n",
        "      if torch.cuda.is_available():\n",
        "        with open(f'{predir}/residuals/{group}_{before}.pkl', 'rb') as f:\n",
        "          residuals1[group][before] = pickle.load(f)\n",
        "      else:\n",
        "        with open(f'{predir}/residuals/{group}_{before}.pkl', 'rb') as f:\n",
        "          residuals1[group][before] = CPU_Unpickler(f).load()\n",
        "    except:\n",
        "      print(f\"No residuals for {group} before {before}\")\n",
        "      residuals1[group][before] = [[0],[0],[0],[0]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKNRIfk0vnSX",
        "outputId": "7899f290-1d80-43c2-c15a-71cb0f1cc871"
      },
      "outputs": [],
      "source": [
        "for group in tqdm(group_order):\n",
        "  for before in before_dates:\n",
        "    try:\n",
        "      residuals_train, residuals_val, residuals_before, residuals_after = residuals1[group][before]\n",
        "      # move to cpu, change to numpy array\n",
        "      residuals_train = [float(x.cpu()) for x in residuals_train]\n",
        "      residuals_val = [float(x.cpu()) for x in residuals_val]\n",
        "      residuals_before = [float(x.cpu()) for x in residuals_before]\n",
        "      residuals_after = [float(x.cpu()) for x in residuals_after]\n",
        "      residuals1[group][before] = (residuals_train, residuals_val, residuals_before, residuals_after)\n",
        "    except:\n",
        "      print(f\"No residuals for {group} before {before}\")\n",
        "      residuals1[group][before] = [[0],[0],[0],[0]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3OvrkSG95lZ"
      },
      "outputs": [],
      "source": [
        "with open(f'{predir}/residuals/residuals1.pkl', 'wb') as f:\n",
        "  pickle.dump(residuals1, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysOTm9iCbKUY"
      },
      "source": [
        "## Split 1a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NnRnBGRwPqs",
        "outputId": "cf757b80-fd25-47c8-b3b0-0af0b6d49759"
      },
      "outputs": [],
      "source": [
        "date_policy1 = pd.to_datetime('2024-02-09')\n",
        "earliest_before = pd.to_datetime('2023-10-1')\n",
        "\n",
        "before_dates1a = pd.date_range(start=earliest_before - pd.Timedelta(days=1), end=date_policy1 - pd.Timedelta(days=14), freq='7D')[:4] + pd.Timedelta(days=1)\n",
        "before_dates1a = before_dates1a[1:] # 0th value is the same as split 1, can use the same models and residuals\n",
        "len(before_dates1a), before_dates1a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_WVBk8CeNTR"
      },
      "source": [
        "#### getting residuals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGWqOWkSbJeZ",
        "outputId": "3c152d40-651b-40f8-f098-0b5b46549074"
      },
      "outputs": [],
      "source": [
        "data_after = data[data['date'] >= date_policy1]\n",
        "for group in tqdm(['zionist','palestine']):\n",
        "  data_after_group = data_after[data_after['group'] == group]\n",
        "\n",
        "  data_group = data[data['group'] == group]\n",
        "  for before in before_dates1a[:2]:\n",
        "    data_before_group = data_group[data_group['date'] < before]\n",
        "    if len(data_before_group) < 100:\n",
        "      print(f\"Not enough data for {group} before {before}\")\n",
        "    else:\n",
        "      # dataloaders\n",
        "      train_loader, val_loader = df_to_traintest(data_before_group, TwoBranchPrepData)\n",
        "      after_loader = data_loader(data_after_group, TwoBranchPrepData)\n",
        "\n",
        "      # train\n",
        "      model = TwoBranchLikesPredictor(\n",
        "          sbert_dim = 384, reachback_length=REACHBACK\n",
        "      ).to(device)\n",
        "\n",
        "      model, train_loss_history, val_loss_history = train_model(model, train_loader, val_loader, lr=0.001, num_epochs= 20, verbose = False)\n",
        "\n",
        "      torch.save(model.state_dict(), f'{predir}/models/{group}_{before}_a.pt')\n",
        "\n",
        "      # get residuals\n",
        "      model.eval()\n",
        "      residuals_train, residuals_val, residuals_before, residuals_after = [], [], [], []\n",
        "      with torch.no_grad():\n",
        "          for inputs, targets in train_loader:\n",
        "              inputs, targets = inputs.to(device), targets.to(device)\n",
        "              outputs = model(inputs)\n",
        "              residuals_train.extend(targets - outputs.squeeze())\n",
        "              residuals_before.extend(targets - outputs.squeeze())\n",
        "\n",
        "      with torch.no_grad():\n",
        "          for inputs, targets in val_loader:\n",
        "              inputs, targets = inputs.to(device), targets.to(device)\n",
        "              outputs = model(inputs)\n",
        "              residuals_val.extend(targets - outputs.squeeze())\n",
        "              residuals_before.extend(targets - outputs.squeeze())\n",
        "\n",
        "      with torch.no_grad():\n",
        "          for inputs, targets in after_loader:\n",
        "              inputs, targets = inputs.to(device), targets.to(device)\n",
        "              outputs = model(inputs)\n",
        "              residuals_after.extend(targets - outputs.squeeze())\n",
        "\n",
        "      group_residuals = (residuals_train, residuals_val, residuals_before, residuals_after)\n",
        "      with open(f'{predir}/residuals/{group}_{before}_a.pkl', 'wb') as f:\n",
        "        pickle.dump(group_residuals, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3N5MyugZcfCy",
        "outputId": "d2cc2fc7-f5e3-4d31-810b-dc0d1ae0f9f0"
      },
      "outputs": [],
      "source": [
        "residuals1a = dict()\n",
        "for group in tqdm(['palestine','zionist']):\n",
        "  residuals1a[group] = dict()\n",
        "  for before in before_dates1a:\n",
        "    try:\n",
        "      with open(f'{predir}/residuals/{group}_{before}_a.pkl', 'rb') as f:\n",
        "        residuals1a[group][before] = pickle.load(f)\n",
        "    except:\n",
        "      print(f\"No residuals for {group} before {before}\")\n",
        "      residuals1a[group][before] = [[0],[0],[0],[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKJWxtedb7WR",
        "outputId": "360fc155-eddf-4778-a20c-0ee373291ffe"
      },
      "outputs": [],
      "source": [
        "for group in tqdm(['palestine','zionist']):\n",
        "  for before in before_dates1a:\n",
        "    try:\n",
        "      residuals_train, residuals_val, residuals_before, residuals_after = residuals1a[group][before]\n",
        "      # move to cpu, change to numpy array\n",
        "      residuals_train = [float(x.cpu()) for x in residuals_train]\n",
        "      residuals_val = [float(x.cpu()) for x in residuals_val]\n",
        "      residuals_before = [float(x.cpu()) for x in residuals_before]\n",
        "      residuals_after = [float(x.cpu()) for x in residuals_after]\n",
        "      residuals1a[group][before] = (residuals_train, residuals_val, residuals_before, residuals_after)\n",
        "    except:\n",
        "      print(f\"No residuals for {group} before {before}\")\n",
        "      residuals1a[group][before] = [[0],[0],[0],[0]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwrepUwkcDmT"
      },
      "outputs": [],
      "source": [
        "with open(f'{predir}/residuals/residuals1a.pkl', 'wb') as f:\n",
        "  pickle.dump(residuals1a, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsCXOrvA0Pvx"
      },
      "source": [
        "# split 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5j1It-0G0Pvz",
        "outputId": "4505b2b9-0bf2-403b-da62-12be95782ab0"
      },
      "outputs": [],
      "source": [
        "date_policy2 = pd.to_datetime('2025-01-07')\n",
        "earliest_before = pd.to_datetime('2024-09-01')\n",
        "\n",
        "before_dates = pd.date_range(start=earliest_before - pd.Timedelta(days=1), end=date_policy2 - pd.Timedelta(days=14), freq='1ME') + pd.Timedelta(days=1)\n",
        "len(before_dates), before_dates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neT_WSDq0Pv0"
      },
      "outputs": [],
      "source": [
        "models2 = dict()\n",
        "residuals2 = dict()\n",
        "\n",
        "data_after = data[data['date'] >= date_policy2]\n",
        "# for group in tqdm(group_order):\n",
        "for group in ['queer']:\n",
        "  data_after_group = data_after[data_after['group'] == group]\n",
        "\n",
        "  data_group = data[data['group'] == group]\n",
        "  for before in before_dates:\n",
        "    data_before_group = data_group[data_group['date'] > date_policy1]\n",
        "    data_before_group = data_group[data_group['date'] < before]\n",
        "    if len(data_before_group) < 100:\n",
        "      print(f\"Not enough data for {group} before {before}\")\n",
        "    else:\n",
        "      # dataloaders\n",
        "      train_loader, val_loader = df_to_traintest(data_before_group, TwoBranchPrepData)\n",
        "      after_loader = data_loader(data_after_group, TwoBranchPrepData)\n",
        "\n",
        "      # train\n",
        "      model = TwoBranchLikesPredictor(\n",
        "          sbert_dim = 384, reachback_length=REACHBACK\n",
        "      ).to(device)\n",
        "\n",
        "      model, train_loss_history, val_loss_history = train_model(model, train_loader, val_loader, lr=0.001, num_epochs= 20, verbose = False)\n",
        "\n",
        "      torch.save(model.state_dict(), f'{predir}/models2/{group}_{before}.pt')\n",
        "\n",
        "      # get residuals\n",
        "      model.eval()\n",
        "      residuals_train, residuals_val, residuals_before, residuals_after = [], [], [], []\n",
        "      with torch.no_grad():\n",
        "          for inputs, targets in train_loader:\n",
        "              inputs, targets = inputs.to(device), targets.to(device)\n",
        "              outputs = model(inputs)\n",
        "              residuals_train.extend(targets - outputs.squeeze())\n",
        "              residuals_before.extend(targets - outputs.squeeze())\n",
        "\n",
        "      with torch.no_grad():\n",
        "          for inputs, targets in val_loader:\n",
        "              inputs, targets = inputs.to(device), targets.to(device)\n",
        "              outputs = model(inputs)\n",
        "              residuals_val.extend(targets - outputs.squeeze())\n",
        "              residuals_before.extend(targets - outputs.squeeze())\n",
        "\n",
        "      with torch.no_grad():\n",
        "          for inputs, targets in after_loader:\n",
        "              inputs, targets = inputs.to(device), targets.to(device)\n",
        "              outputs = model(inputs)\n",
        "              residuals_after.extend(targets - outputs.squeeze())\n",
        "\n",
        "      group_residuals = (residuals_train, residuals_val, residuals_before, residuals_after)\n",
        "      with open(f'{predir}/residuals2/{group}_{before}.pkl', 'wb') as f:\n",
        "        pickle.dump(group_residuals, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02IBQCaI0Pv2",
        "outputId": "20e13044-ef6f-4529-f35e-e35133b023bb"
      },
      "outputs": [],
      "source": [
        "for group in tqdm(group_order):\n",
        "  for before in before_dates:\n",
        "    try:\n",
        "      residuals_train, residuals_val, residuals_before, residuals_after = residuals2[group][before]\n",
        "      # move to cpu, change to numpy array\n",
        "      # residuals_train = [float(x.cpu()) for x in residuals_train]\n",
        "      # residuals_val = [float(x.cpu()) for x in residuals_val]\n",
        "      # residuals_before = [float(x.cpu()) for x in residuals_before]\n",
        "      # residuals_after = [float(x.cpu()) for x in residuals_after]\n",
        "      residuals_train = [float(x) for x in residuals_train]\n",
        "      residuals_val = [float(x) for x in residuals_val]\n",
        "      residuals_before = [float(x) for x in residuals_before]\n",
        "      residuals_after = [float(x) for x in residuals_after]\n",
        "      residuals2[group][before] = (residuals_train, residuals_val, residuals_before, residuals_after)\n",
        "    except:\n",
        "      print(f\"No residuals for {group} before {before}\")\n",
        "      residuals2[group][before] = [[0],[0],[0],[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfhi6VE8-BNa"
      },
      "outputs": [],
      "source": [
        "with open(f'{predir}/residuals/residuals2.pkl', 'wb') as f:\n",
        "  pickle.dump(residuals2, f)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
